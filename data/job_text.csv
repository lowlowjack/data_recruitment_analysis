Company,Role,Responsibility,Qualifications
Ideagen,AI Technical Product Owner,"We are seeking for an experienced Product Owner with deep understanding of AI technologies. As a Level 2 Technical Product Owner, you will play a pivotal role in driving the development, delivery and success of AI-driven products and solutions. You will work closely with multiple Product Managers and cross functional teams to understand the problems and opportunities to be addressed, prioritise features, and ensure the timely delivery of high-quality products. This is an exceptional opportunity to make a significant impact in a fast-paced and dynamic environment while staying at the forefront of the latest
advancements in AI.

Requirements Gathering: Collaborate closely with product managers to comprehensively gather and document product requirements, ensuring a clear understanding of desired outcomes.
• Stakeholder Management: Engage proactively and maintain open lines of communication with key stakeholders, including Product Managers, Development teams, and other pertinent business and technical stakeholders. This involves addressing inquiries promptly, gathering valuable feedback, aligning expectations, and furnishing regular updates on the progress of product development initiatives.
• User Story Development and Refinement: Decompose high-level requirements into actionable user stories with well-defined acceptance criteria, ensuring the development team grasps the scope of work accurately.
• Backlog Management: Maintain and prioritize the product backlog meticulously, ensuring user stories and tasks are precisely defined, estimated, and prioritized based on business value and customer needs.
• Sprint Planning: Lead sprint planning sessions, collaborating with the development team to determine the sprint's scope and establish realistic and achievable goals.
• Sprint Review: Participate in sprint review sessions to verify that the product aligns with customer expectations, gathering feedback for continuous improvement.
• Sprint Retrospective: Participate in retrospective sessions to identify areas for enhancement and implement lessons learned, fostering a culture of continuous improvement within the team. Observe key metrics to identify areas of improvements.
• Product Documentation: Contribute to the creation and maintenance of comprehensive product documentation, including personas, customer journey maps, user manuals, release notes, and feature descriptions, ensuring accuracy and completeness.
• Agile Development Process: Embrace agile principles and ways of working, such as Scrum or Kanban, to facilitate iterative and incremental development.
• Project Management: Track project progress, identify risks and implement mitigation strategies to ensure timely delivery of high-quality products","Proven AI Expertise: Demonstrated experience (2+ years) as an AI Product Owner or in a similar role, preferably within an Agile software development environment. Anyone who is interested in the AI domain is encouraged to apply.
• Agile Expertise: Proficiency with Agile tools like JIRA or Trello, coupled with familiarity with Agile ways of working such as Scrum or Kanban, is highly desirable.
• SaaS Proficiency: Experience with the deployment and development of SaaS software solutions is advantageous.
• Strong Analytical Skills: Ability to dissect complex problems, break them down into manageable components, and propose effective solutions.
• Excellent Communication: Exceptional verbal and written communication skills are essential, with the capability to articulate ideas and requirements clearly and effectively to technical and non-technical stakeholders across cultures and organizational levels.
• Collaborative Nature: Ability to thrive in a team-oriented, cross-functional environment, fostering relationships and promoting collaboration.
• Attention to Detail: Meticulous organizational skills with an attention to detail, ensuring accurate documentation and tracking of requirements and deliverables.
• Adaptability: Comfortable operating in a fast-paced, dynamic environment, with the flexibility to swiftly adapt to shifting priorities and evolving business needs.
• Passion for Technology: Enthusiasm for emerging technologies, software development processes, and a commitment to staying abreast of the latest industry trends.
• Self-Motivation: A proactive individual who demonstrates ownership of tasks and exhibits the drive to learn, grow, and undertake additional responsibilities autonomously."
Loom.com,Senior Data Scientist,"Collaborate on a variety of product and business problems with a diverse set of cross-functional partners and become a trusted strategic partner through the structure and clarity of your work.

Apply technical expertise with quantitative analysis, experimentation, and the presentation of data to develop strategies for our business and help solve the business's biggest challenges.

Focus on developing hypotheses through analytical approaches, different methodologies, frameworks, and technical approaches to test them.

Define, understand, and test opportunities to improve the products and business and influence roadmaps through insights and recommendations.

Partner with cross-functional teams to inform, influence, and execute strategy decisions

Identify and measure the success of product efforts through forecasting and monitoring of key product metrics to understand trends.

You will use data to shape product development, quantify new opportunities, identify upcoming challenges, and ensure the products we build bring value to people, businesses, and Atlassian.","5+ years of experience in an analytics role turning data into insights and recommendations

Strong analytical and communication skills with the ability to synthesize insights into compelling stories

Experience with the SaaS customer lifecycle from acquisition to retention

Experience with designing and analyzing experiments

Superior SQL (Snowflake, Postgres) skills - able to write structured and efficient queries on large data sets

Experience with a Business Intelligence tool (e.g. Tableau or Hex)

Experience with a statistical scripting language (e.g. R or Python) is a plus"
Petraware technologies,Business Analyst,"Gather and analyze user requirements, offering solutions to clients.
Create documentation including user requirements, functional specifications, test scripts, user guides, and training materials.
Participate in application testing to ensure system functionality meets requirements.
Support implementation and training as needed.
Act as a liaison between the development team and stakeholders throughout the implementation process.
Conduct research and analysis on Asset Management technologies.
Recommend improvements to business processes, reports, and applications to enhance system efficiency.
Handle any ad-hoc tasks as assigned by the End User.","Bachelor's degree in Computer Science, Information Technology, Business Studies, Management, or a related field.
1-3 years of experience in Unit Trust, Asset Management, finance, or accounting preferred.
Strong analytical and problem-solving skills.
Excellent written and verbal communication skills in English; proficiency in additional languages is a plus.
Outgoing, resourceful self-starter with strong interpersonal skills.
Knowledge of Unit Trust processes, digital transformation, and user experience is beneficial.
Willingness to travel and accept overseas assignments if needed.
Ability to work independently and as part of a team.
Fresh graduates are encouraged to apply."
Agoda.com,Data Analyst,"Search: Experiment with text ads, bidding, and campaign structures on Google, Bing, Baidu, Naver, and other search engines. Adapt to new product features and roll out changes from successful tests.
Display: Test, analyze, and optimize campaigns on Facebook, Twitter, Instagram, and others.
Modeling: Analyze the vast amounts of data generated by experiments, develop models we can use for optimization, and build dashboards for account managers.","Bachelor’s Degree or higher from top university in a quantitative subject (computer science, mathematics, engineering, statistics or science)
Ability to communicate fluently in English
Exposure to one or more data analysis packages or databases, e.g., SAS, R, SPSS, Python, VBA, SQL, Tableau
Good numerical reasoning skills
Proficiency in Excel
Intellectual curiosity and analytical skills"
Agoda.com,Senior Data Engineer,"Lead the team technically in improving scalability, stability, accuracy, speed and efficiency of our existing Data systems
Build, administer and scale data processing pipelines.
Be comfortable navigating the following technology stack: Scala, Spark, java, Golang, Python3, scripting (Bash/Python), Hadoop, SQL, S3 etc.
Improve scalability, stability, accuracy, speed and efficiency of our existing data systems
Design, build, test and deploy new libraries, frameworks or full systems for our core systems while keeping to the highest standards of testing and code quality
Work with experienced engineers and product owners to identify and build tools to automate many large-scale data management / analysis tasks","Bachelor’s degree in Computer Science /Information Systems/Engineering/related field
5+ years of experience in software and data engineering
Good experience in Apache Spark
Expert level understanding of JVM and either Java or Scala
Experience debugging and reasoning about production issues is desirable
A good understanding of data architecture principles preferred
Any other experience with Big Data technologies / tools
SQL experience
Analytical problem-solving capabilities & experience.
Systems administration skills in Linux"
Ola Chat,Data Analyst,"1.Understand the company’s live streaming business, establish data metrics, track reporting, and ensure data accuracy.

2.Coordinate with business departments, provide data statistics and analysis support, offer data dashboards and related conclusions, and propose data suggestions.

3.Analyze fluctuations in business data for specific scenarios, drive problem identification and improvement, assist in product optimization, and track optimization results.

4.Analyze existing business data, assist in building a user tag system framework, and achieve refined business operations.

5.Responsible for data analysis of B-end operational strategies, evaluating the effectiveness of strategies from dimensions such as revenue, cost, return on investment, etc., and assisting the operational department in formulating operational strategies.

6.Collect public data, conduct user demand research, and complete business-themed commercial analysis.","1.Bachelor’s degree or above in statistics, mathematics, computer science, or related fields, with more than 2 years of experience in data development and analysis.

2.Proficient in using SQL language for various complex data processing and summary statistical analysis, able to quickly master BI software, familiarity with visualization software such as Tableau is preferred.

3.Proficient in Excel (MS-MVP is a plus), including pivot tables, functions, charts, etc.

4.Strong logical thinking ability, clear expression, adept at expressing viewpoints with data.

5.Self-driven, with strong independent work and problem-solving abilities, able to handle work pressure."
HTC Global Services,Data Analyst,,"Analytical skills in analysing numbers and trends

Attention to detail and sound problem solving skills

Advanced competency in Excel

Proficiency in database management and data analysis tools (e.g., SQL, Excel, Tableau)

Possess basic programming skills"
Logicalis Asia Pacific,Analytics Consultant,"Extracts knowledge and insights from data in order to investigate complex business problems through a range of data preparation, modeling, analysis and/or visualization techniques, including predictive analysis, business intelligence, pattern recognition, operational effectiveness and/or economic forecasting. ","Key skills include data analysis techniques (e.g., A/B testing, association rule learning, cluster analysis, pattern recognition and predictive modeling), data analysis and visualization software (e.g., Domo, Looker, PowerBI, Qlik, Tableau, SiSense), object-oriented programming languages (Java, Python, R, Ruby, Scala, C++) and/or data engineering skills (relational or NoSQL databases, ETL tools).

Has working knowledge and experience in own discipline
 Continues to build knowledge of the organization, processes and customers
 Performs a range of mainly straightforward assignments
 Uses prescribed guidelines or policies to analyze and resolve problems
 Receives a moderate level of guidance and direction
 Typically follows prescribed guidelines or procedures to resolve problems
 Has working knowledge of basic concepts and procedures; performs a variety of routine tasks or assignments
 May train new team members and provide input to employee performance evaluations
 Works with a moderate level of guidance"
Emerson,Group Manager of Customer Data Management,"Develop and implement a comprehensive customer master data management strategy aligned with the company's goals and objectives. 
Establish and implement data governance policies, standards, and procedures to ensure data integrity, accuracy, and compliance with regulatory requirements. 
Be responsible for the design, implementation, and maintenance of customer master data management systems, tools, and technologies. 
Collaborate with IT teams to ensure magnificent integration of customer master data across various systems and platforms. 
Define and supervise data quality metrics, proactively identify data issues, and implement corrective actions. 
Drive data cleansing, enrichment, and standardization initiatives to improve data quality and consistency. 
Establish and maintain data stewardship processes, roles, and responsibilities. 
Provide leadership and mentorship to a team of data management professionals, fostering a culture of continuous learning and development. 
Collaborate with business partners to understand data requirements, resolve data-related issues, and support data-driven initiatives. 
Stay ahead of with industry trends, best practices, and emerging technologies in customer master data management. 
Contribute to and lead global initiatives that are dedicated to process alignment, policy consistency, task prioritization, timely delivery, problem solving, and collaborative learning.
Initiative to excel in a dynamic and fast paced environment and not afraid of doing “hands on” work occasionally. ","BS in Economics, Statistics, Operations Research, Computer Science, Business Administration, or a related field.. 
Demonstrable experience (minimum 5 years) in managing customer master data, preferably in a leadership role. 
Solid understanding of data management principles, data governance, and data quality management. 
Experience implementing and managing customer master data management systems, tools, and technologies. 
Familiarity with data integration and data migration techniques. 
Excellent leadership and people management skills, with a track record of building and developing high-performing teams. 
Good communication and interpersonal skills, with the ability to collaborate effectively with multi-functional teams and senior partners. 
Goal-focused attitude with the capability to initiate change, handle various tasks, and meet timeframes. 
Diligent in ensuring detail and precision. 
Knowledge of industry standards and regulations related to customer data management."
Experian,Data Analyst,"Data Analysis and Reporting: Utilize Snowflake for querying and analysing large datasets, and create meaningful reports and visualizations in Jupyter or dataviz tools such as Tableau and Superset.
Data Transformation and Modeling: Employ dbt to structure and transform data to optimize analysis and reporting.
Workflow Management: Develop and manage workflows (we have a preference for Dagster/Python) to ensure data quality and consistency across tasks.
Collaborative Projects: Work closely with data engineers and other analysts to refine data collection and analysis processes.","Education and Experience: Degree in Computer Science, Information Systems, Statistics, or a related field. At least 3 years of experience in a data analyst role, preferably with exposure to the modern data stack and cloud data infrastructure

Curiosity. We value above all an individual that's curious about the job that's being done.
Technical Proficiency: You must be a SQL wizard, we'd love experience with cloud data platforms like Snowflake. Proficiency in Python, especially in a data context using Jupyter and orchestration tools such as Airflow and Dagster
Data Transformation Skills: Experience with data build tool (dbt) or ELT paradigm for transforming data in a warehouse environment
Analytical Skills: Ability to derive insights from complex data sets and present them in a clear and concise manner.
Communication: Excellent verbal and written communication skills to effectively share findings and collaborate with team members.
Desirable: Experience with data visualization tools (Tableau, PowerBI or Superset), Knowledge of additional programming languages or analytics tools. Ability to innovate and show initiative"
Manatal,Senior Data Scientist,"Set, define, and own the data science roadmap
Build, maintain, and enhance Manatal core features focus on
- CV/Resume parsing in multiple languages
- Candidate recommendation engine
- Social media enrichment for candidates 
Independently manage each part of a project life cycle, including ad-hoc exploration, preparation of training data, model development, and production deployment 
Design, prototype, and implement solutions across several domains 
Help define and implement a framework of continual innovation 
Partner with engineers to develop ML projects, and maintain high system availability and reliability ","BA/BS in Mathematics, Statistics, or Computer Science is required or a Master's degree in a quantitative scientific discipline is strongly desired 
Advanced statistical modelling skillset
Advanced SQL querying, data mining, and data cleaning skillset 
Excellent knowledge of Python, including common scientific computing packages and data science tools such as NumPy, Pandas, NLP libraries, Tensorflow and Scikit-learn
Good knowledge of supervised and unsupervised machine learning algorithms (neural networks, decisions, trees, etc.) 
Advanced knowledge of experiment design 
Hands-on experience with cloud infrastructure tools (AWS, EC2, S3, Lambda, Data Engineering)
Advanced visualization/reporting and presentation experience 
Version Control Experience (GitHub)
Knowledge of web applications and service-oriented architecture
Excellent strategic project planning skillset 
Excellent communication skills (written and verbal)
Experience at a B2B SaaS company is a plus"
Gate.io,Big Data Engineer,"Responsible for the construction, operation, maintenance, management, and troubleshooting of the big data platform.
Responsible for ensuring the efficient operation, stability, and security of the big data platform, and providing solutions for cluster upgrades and expansion.
Capable of optimizing the configuration of various platform components, such as Hadoop, YARN, Kafka, Flink, Doris, MySQL, PostgreSQL, etc.
Responsible for the deployment and launch of big data tasks, familiar with common issues in task execution, and formulating contingency plans","Bachelor's degree or above in computer-related fields, with more than 5 years of work experience.
Familiar with big data platforms, with experience in building and maintaining big data systems; experience with AWS EMR platform is preferred.
Familiar with Hadoop ecosystem components, understanding of underlying principles, and experience in configuration optimization, such as Hadoop, YARN, Flink, Kafka, etc.
Familiar with data analysis SQL syntax; candidates with SQL optimization experience are preferred.
Proficient in the operation and maintenance of databases such as MySQL, PostgreSQL, Elasticsearch, Doris, etc.
Possesses good communication skills, learning ability, written expression skills, and a high degree of self-motivation."
Accenture,Analytics/ML Engineer,"Ease the adoption of a federated computing software (e.g. NVFLARE, DataShield)
Create quick starts / data scientists oriented how-to guides explaining step-by-step e.g. how to convert from centralized to federated code
Contribute to the development and testing of a secure and privacy-preserving federated computing platform and participate in technical design and implementation of the user workflows in a federated setting (incl. at network level)
Assist in developing and applying of federated analysis scripts / notebooks for RWD/clinical analysis e.g. descriptive cohort statistics, time series analysis
Facilitates the testing and validation of models to determine viability for federated deployment
Actively collaborate with PDD/PHC/RWD data scientists to design and assist in the creation of a statistical analysis plan according to a scientific protocol in a federated setting
Stay up to date with the latest advances in federated computing (FA/FL)
Communicate results and findings to the team and stakeholders in a clear and concise manner
Contribute to methodological research in FA/FL to unlock novel analytical/ML approaches (e.g. privacy-preserving functions) in collaboration with data scientists and researchers
Review code developed by others and provide feedback to ensure best practices (e.g. disclosure, style guidelines, checking code in, accuracy, testability and efficiency)
Contribute to existing documentation or educational content and adapt content based on platform updates and user feedback","Passionate about the intersections of healthcare and analytics/AI and software engineering and data engineering
Sound knowledge and experience in data science workflows and expertise on multi-modal datasets (among RWD, clinical, imaging, biomarker, omics)
Experience with ML model deployment and lifecycle management and in particular with building, testing, measuring, and deploying machine learning models in production
Practical understanding of different anonymization and privacy-preserving techniques (nice-to-have)
Familiarity with machine learning concepts and toolkits such as: cross validation, experiment tracking, statistical tests; scikit learn, xgboost, etc.
Sound technical and computing scripting / programming skills: Python, R, Pandas, Numpy, PyTorch ML, TensorFlow ML, Matplotlib, Jupyter, Git, Bash/Linux basics
Good knowledge of software development best practices including testing, continuous integration, and DevOps tools
Beneficial technical skills: NVIDIA FLARE, Apheris, DataSHIELD, AWS administration, Docker, Kubernetes, Kubeflow, MONAI"
Accenture,Data Scientist,"Although no two days at Accenture are the same, as an Organizational Analytics (OA) Scientist – Analyst in our HR-T&O practice, a typical day might include:

Leverage a data-driven approach to develop tailored employee listening solutions for global and local clients, including:
 

1. Designing Bespoke Frameworks:

Collaborate closely with clients to understand their business context, challenges, and goals, ensuring tailored Organizational Analytics (OA) solutions.
Develop customized employee listening frameworks that integrate secondary research, organizational psychology theories, and industry best practices.
Work with clients to refine and design questionnaires that align with organizational objectives and accurately capture critical data.
 
2. Data Processing & Validation:

Cleanse, process, and verify data to ensure its integrity and reliability for accurate analysis.
Conduct inter-rater agreement analysis to ensure the face validity of questionnaires, enhancing their precision and effectiveness.
Use Exploratory Factor Analysis (EFA) to validate construct structures, ensuring reliable measurement of underlying factors in assessments.
 
3. Application of Technical Expertise:

Leverage R-Programming or Python to identify trends, patterns, and insights from complex datasets.
Implement advanced statistical methodologies like t-tests, regressions, cluster analysis, and random forest models to derive actionable insights.
Apply variable selection methods, self-organizing maps, and predictive analytics to optimize data models using primary datasets.
 
4. Insight Generation:

Synthesize data from organizational assessments and focus groups to produce strategic, high-level reports.
Present clear, actionable insights to clients, supporting data-driven decision-making.
Interpret analytics outputs, such as heat maps, and design summary slides with demographic insights to communicate findings effectively.
Conduct ad-hoc analyses to deliver timely and customized insights to meet client needs.
Contribute to the development of innovative products and solutions in the people and organizational analytics space.
Author thought leadership articles and research papers to advance knowledge in the field of Organizational Analytics.","Bachelor’s / Masters in Psychology
1 to 3 years of experience in psychometric assessment development and organizational psychology research
Related industry experience such as business data analysis for people management-related programs such as culture transformation and talent strategy, change strategy, stakeholder assessment, change impact analysis, organization design, and digital learning readiness, etc.
Data fluency and working to advanced knowledge of statistical methodologies.
Fluency in English
Ability to perform in a non-structured and dynamic environment
Basic knowledge of data visualization tools like Power BI or Figma over the past 1 year is advantageous.
Desirable: Experience with qualitative research tools such as NVivo and Remesh in the last 1-2 years."
Ria Money Transfer,Data Analyst," Work as a Data Analyst engineer in a globally distributed team.
•   Take part in daily meetings (agile) to follow up with the work of the team.
•   Integrate with the coding guidelines of the company.
•   Research and prototype with the latest technologies to improve the applications.
•   Analyze, design, document, develop, maintain and provide support for the applications.
•   Deliver the tasks as scheduled by the Technical Lead.

Work with analysis documents, functional documents or technical documents to elaborate data extractions to fulfill operational and business teams.
•   Analysis and improvement of query performance for existing reports, stored procedures and queries.
•   Provide level 3 support to the stakeholders and end users.
•   Understand business requirements and provide technical solutions.
•   Deliver the tasks as scheduled by the Technical Lead.
•   Participate in agile meetings to follow up on the team tasks to achieve the goals.","Education and Experience
 

Degree in Computer Science or equivalent.
2+ years of overall experience in Microsoft Business Intelligence Stack:
Microsoft SQL Server.
Reporting Services.
Integration Services.
Proficient In English (verbal and written).
Team worker and proven abilities to take initiative and be innovative
Analytical mind with a problem-solving aptitude
Passionate team worker.
Self-starter who is comfortable working in teams. Someone who is not afraid to get their hands dirty and knock doors to have the products delivered.
A proven self-starter with strong communication and presentation skills - ability to translate complex business problems into technical solutions.
Ability to articulate the “why” behind your decisions clearly to the team and other stakeholders. 
Technologies Required:

SSRS
SSIS
MS T-SQL
Git

Nice to have:
 

Knowledge in Power BI (Power Query and Dax).
Microsoft Power Automate.
Background in data warehouse.
In-depth understanding of database management systems, online analytical processing (OLAP) and ETL framework
Experience in development teams following SCRUM, XP or KANBAN methodologies.
Background in financial services applications with experience in high transaction volume environment."
HCL Tech,Qliksense Data Engineer,"
Analyze data to identify trends and insights.

Develop and maintain Qlik Sense reports and dashboards.

Ensure data accuracy and integrity in reports.

Design and develop Qlik Sense applications.

Implement data models and visualizations.

Optimize Qlik Sense applications for performance.

Integrate data from various sources into Qlik Sense.

Ensure seamless data flow and connectivity.

Troubleshoot and resolve data integration issues.

Provide support to end-users for Qlik Sense applications.

Conduct training sessions to help users understand and utilize Qlik Sense effectively.

Address user queries and issues promptly.

Collaborate with business stakeholders to understand requirements.

Communicate effectively with team members and stakeholders.

Document processes and solutions clearly.

Stay updated with the latest Qlik Sense features and best practices.

Suggest and implement improvements to existing Qlik Sense applications.

Participate in knowledge-sharing sessions and team meetings.
","Experience : 4+yrs

Data Analysis and Reporting

Qlik Sense Development

Data Integration

User Support and Training

Collabration and communication

Continuous improvement mindset"
Keysight Technologies,Data Scientist,"End-to-end delivery of data analytics projects including project framework, analysis technique and implementation of data science models
Analyse and interpret large volume and complex datasets to extract insights, trends, and patterns, helping organizations make data-driven decisions.
Integrate external factor and global context into analytical models to enhance predictive accuracy and provide a broader context for decision making.
Apply various data science technologies: statistical analysis, machine learning and pattern recognition with subject-specific modelling to address opportunities in business performance and achieve supply chain efficiencies.
Design experiments and statistical tests to validate hypotheses.
Present findings to non-technical stakeholders in a clear and understandable manner","A bachelor's degree in a quantitative field such as Data Science, Statistics, Mathematics, Physics, or related fields, with a minimum of 5 working years of experience.
Strong background in statistics and probability theory is essential for analyzing and interpreting complex data.
Proficiency in programming languages commonly used in data science, such as Python or R. Familiarity with tools like SQL for database querying is also valuable.
Understanding and practical experience with machine learning techniques and algorithms. This includes supervised and unsupervised learning, regression, classification, clustering, and more.
Ability to create meaningful visualizations to communicate complex findings effectively. Familiarity with tools like Matplotlib, Seaborn, or Tableau can be beneficial.
Strong communication skills to explain complex technical findings to non-technical stakeholders and decision-makers.
Having supply chain knowledge will be an added advantage."
Keysight Technologies,AI Engineer Intern,"The responsibilities of an AI Engineer intern include assisting in the development and implementation of AI models and algorithms, analyzing large datasets to extract meaningful insights, supporting machine learning projects, and collaborating with teams to enhance AI-driven solutions. The intern will also contribute to optimizing AI systems and help automate processes for improved efficiency and innovation.
",
Swift,Business Analyst,"Translate requirements into detailed data models by taking data architecture design and implementation roadmap into account.
Perform feasibility analysis with technical counterparts based with thorough understanding of the high-level data model implementation, data collection tools and data distribution systems.
Manage data collection teams. Define their KPIs and evaluate them periodically. Derive from the business data requirements the data management processes.
Train and coach, the data teams applying the data management processes.
Motivate the remote data teams by relating their work to the team’s objectives, customer benefits and SWIFT’s business.
Clearly document the requirement specifications, data models, data definitions, data import specifications for IT, data management processes for the data team, use cases, exceptions, test/review, and acceptance criteria, etc...
Act as the data expert and support your peers and internal and external customers.
Convey the information to the rest of the team through presentations or document walkthroughs.
Understand business data trends in own area of responsibility and apply this knowledge to bring solutions to the end users.
Assist in explaining the implementation approach and timeline to the business.
Work in a scrum team respecting timing and scheduling estimates, propose corrective actions when necessary. Working in a scrum team means striving to maximum flexibility, helping colleagues when needed.","What to expect:
Strong analytical, communication and presentation skills, with excellent English, both written and spoken.
Excellent team player.
Influencing others with and without formal authority.
Well-structured and organized.
Ability to manage remote teams through objectives, targets, and evaluations.
Establish course of actions for self and others to ensure that work is completed with the triple constraint of quality, time, and cost (e.g. quality to be measured by early adopter satisfaction on pilot).
Ability to be patient with others while working under pressure.
Ability to prioritize and focus on the most important issues at hand.
Ability to master complexity by a structured break-down.
Understanding of abstract concepts and structured models and ability to apply them in imperfect reality.
Willingness to build up thorough knowledge of the data content.
Proactivity and drive for continuous improvement.
What will make you successful:
University degree in Data Science, Computer Science, Information Systems, or a related field; or equivalent work experience. Master’s degree an asset.
Typically requires 6 to 10 years’ experience, preferably in similar roles and/or industries.
2+ years in data engineering or 5+ years of IT requirements engineering experience is required, with additional experience in data modelling, software and testing, design or architecture of data bases preferred, or equally through work experience in a payment processing type of environment.
Good experience in structured data engineering techniques (data modelling, data normalisation, state transition diagrams, regular expressions), and with knowledge of Atlassian tools (JIRA, Confluence) is preferred.
Knows Python programming using Jupyter (IDE) will be an added advantage."
AIA Digital+,"Lead Analyst, Cloud Cost Management Engineer","The Lead Analyst, Cloud Optimisation & Governance (FinOps) plays a crucial role in managing the organisation’s Cloud consumption efficiently. The role involves providing timely data, reports, and analysis to aid decision-making, recommending usage and rate optimisation, and ensuring compliance with Cloud policy and FinOps best practice. Additionally, the Lead Analyst will work on process simplification and automation, such as reporting automation and rightsizing automation.

The role will collaborate closely with external stakeholder, including Public Cloud providers, Cloud Cost Management tool providers, Cloud managed service providers, to address any issues promptly.

The role will act as a single point of contact for Cloud consumption related matters on behalf of the Group Cloud & Infrastructure Function
Responsibilities include, but are not limited to, the following:
Prepare routine and ad hoc Cloud consumption reports that provide insights into usage patterns and anomaly detection
Ensure the accuracy of data ingestion from various sources
Support Cloud consumption estimate, forecast and budgeting to ensure high level of spend accuracy
Support target setting for cost optimisation and progress reporting
Provide actionable workload and rate optimisation recommendations, and track implementation progress
Collaborate with Cloud Architect to identify architecture optimisation opportunity
Manage Cloud Cost Management tool and collaborate with tool providers to implement process or tool enhancement
Key contributor to monthly engagement and governance meetings with Local Business Units
Ensure 100% tagging compliance for mandatory fields in the Cloud environment
Aid the IT Finance team with monthly Cloud cost chargeback
Advocates for FinOps best practice to drive continuous improvements
Communication Requirements:
Communication with internal stakeholders including but not limited to local Business Units, Cloud & Infrastructure, Application Owner, IT Security, Finance at all levels, and with external stakeholders such as Public Cloud provider, Cloud Cost Management tool provider, Cloud managed service provider
Excellent command of spoken and written English to allow communication with all levels of stakeholders","Bachelor’s degree in Computer Science, Information Technology, or related field
2+ years relevant experience in Cloud Cost Management, FinOps, Cloud engineering or Cloud architecture
Understanding of Cloud policy & governance, Cloud architecture & workloads onboarding, and Cloud usage & cost,
Proven experience with complex data analysis and data visualisation tools (such as PowerBI)
Proven experience in managing Cloud Cost Management (FinOps) tools
Cloud related professional certifications such as Azure, AWS, FinOps certification
Sound understanding of Finance principles and processes such as budgeting, forecasting, invoicing, and cost optimisation
Experience within regulated industry and regional or multinational scope organization
Special skills:
Ability to demonstrate independent leadership, judgment, and decision making
Ability to adjust to multiple and changing priorities, remaining flexible and open
Ability to create and maintain cooperative working relationships with internal and external stakeholders of peer levels
Commercial acumen and understanding of Cloud Consumption based constructs
Analytical and communication skills to understand business context; and enquire, counsel, and present solutions in an understandable and simple manner
Be a self-starter and possess the confidence and skills to operate well within a team of highly skilled peers."
iSoftStone,Snowflake Lead Developer,"Responsibilities

Create, test, and implement enterprise-level apps with Snowflake
Design and implement features for identity and access management
Create authorization frameworks for better access control
Implement novel query optimization, major security competencies with encryption
Solve performance issues and scalability issues in the system
Transaction management with distributed data processing algorithms
Build, monitor, and optimize ETL and ELT processes with data models
Understand and implement the latest delivery approaches based on data architecture
Project documentation and tracking based on understanding user requirements
Manage documentation of data models, architecture, and maintenance processes
Continually review and audit data models for enhancement
Maintenance of ideal data pipeline based on ETL tools
Coordination with BI experts and analysts for customized data models and integration
Code updates, new code development, and reverse engineering
Performance tuning, user acceptance training, application support
Perform Risk assessment, management, and mitigation plans
Regular engagement with teams for status reporting and routine activities
Migration activities from one database to another or on-premises to cloud","At least 5 years’ experience in enterprise-level Snowflake applications:

Data ingestion into Snowflake
Snowflake modeling – roles, databases, schemas
Performance tuning and setting up resource monitors
SQL performance measuring, query tuning, and database tuning
Using ETL tools to build data warehouses
Managing sets of XML, JSON, and CSV from disparate sources
Knowledge of:

Snowflake warehousing, architecture, processing, administration
SQL language and cloud-based technologies, data warehousing concepts, data modeling, metadata management
SQL-based databases like Oracle SQL Server, Teradata, etc.
Coding in languages like Python, Java, JavaScript
Root cause analysis of models with solutions"
AlphaTrade,Finance Operation & Risk Analyst,"Responsibilities

Produce a regulatory compliance daily reconciliation which measure the Firm’s capital excess over clients monies everyday
Identify any reconciliation breaks and identify them and resolve the queries via internal partners or external vendors such as Banks and Liquidity Providers
Maintain the Firm’s financial records by booking summary level data (mainly available from the daily reconciliation and the Firm’s management accounts on a daily basis
Communicate and implement strategies alongside technical team
Identify and solve weaknesses within the organisation
Explore new ways to increase customer or client satisfaction alongside the executive team
On-board New Clients
","At least previous 3 years work experience in relevant sector (Banking Operations, Accounting Operations (within Financial Services), Securities Services operational and accounting role
BSc in Infosys, Data Analytics or similar technology qualification(s) or BA in Finance or Economics (ideally majoring in Econometrics / Quantitative Analysis or Micro-Economics),
Highly proficient in MS Excel and regular proficiency in MS Office Suite
Strong written and verbal communication skills"
Sunway Medical Centre,Senior Data Engineer,"Job Responsibilities

Cloud-Based Data Management:
Develop and maintain scalable data pipelines on cloud platforms e.g. Microsoft Azure and Huawei Cloud.
Design and implement cloud-native solutions for data ingestion, processing, and analytics.
Ensure optimal integration of big data services with existing systems.
Maintain security and compliance of data solutions in a healthcare context.


2. Data Processing, Transformation, and Optimization:

Lead the optimization of data systems and pipelines in a cloud environment.
Implement data validation, cleansing, transformation, and storage solutions in cloud and data lake environments.
Build ETL/ELT processes to prepare datasets that empower data analysts and other users.
Implement data engineering best practices, including SCD, CDC, and Medallion architecture to ensure efficient data flow.
Oversee the scalability, security, and performance of data pipelines.


3. Data Modeling and Enablement:

Design and build data models and datasets that empower data analysts and business teams to perform their own analysis and reporting.
Collaborate with stakeholders to understand data requirements and ensure data models are aligned with business needs.
Ensure data availability, quality, and consistency across the organization, supporting self-service analytics.


4. Leadership and Team Collaboration:

Provide technical guidance and mentorship in cloud-based data engineering.
Collaborate with different teams to translate business needs into effective cloud data solutions.
Drive cloud data initiatives and foster innovation within the team.


5. Innovation and Problem-Solving:

Explore and implement new technologies and methodologies in cloud big data services.
Lead troubleshooting and problem resolution for data processes in cloud environments.
Stay current with emerging trends and technologies in cloud data management.","Job Qualifications

Expertise in Cloud Big Data Platforms:

Proficient in cloud-based big data services e.g. Microsoft Azure and Huawei Cloud.
Experience in building and managing data solutions in a cloud environment.
Understanding of cloud architecture, data security, and compliance in a healthcare context.
Data Engineering and Analytical Skills:

Strong background in Python, SQL, and big data tools like Hadoop, Spark, PySpark, and Delta Lake.
Solid skills in data modeling and analytics in a cloud setting.
Ability to derive insights and solutions from complex data sets.
Communication and Collaboration:

Effective communication skills with both technical and non-technical teams.
Strong collaboration abilities, working effectively in a team setting.
Problem-Solving and Innovation:

Skilled in identifying and solving data-related challenges in cloud environments.
Adept at staying ahead of the curve in cloud data technologies and practices.
Technical Proficiency:

Deep understanding of technical concepts in data engineering and cloud computing.
Experience with quality assurance and testing of cloud-based data products."
Sherwin Williams,Junior Data Engineer,"Job Qualifications

Expertise in Cloud Big Data Platforms:

Proficient in cloud-based big data services e.g. Microsoft Azure and Huawei Cloud.
Experience in building and managing data solutions in a cloud environment.
Understanding of cloud architecture, data security, and compliance in a healthcare context.
Data Engineering and Analytical Skills:

Strong background in Python, SQL, and big data tools like Hadoop, Spark, PySpark, and Delta Lake.
Solid skills in data modeling and analytics in a cloud setting.
Ability to derive insights and solutions from complex data sets.
Communication and Collaboration:

Effective communication skills with both technical and non-technical teams.
Strong collaboration abilities, working effectively in a team setting.
Problem-Solving and Innovation:

Skilled in identifying and solving data-related challenges in cloud environments.
Adept at staying ahead of the curve in cloud data technologies and practices.
Technical Proficiency:

Deep understanding of technical concepts in data engineering and cloud computing.
Experience with quality assurance and testing of cloud-based data products.","FORMAL EDUCATION: 

Bachelor's Degree in Computer Science, Engineering or a related field.
KNOWLEDGE & EXPERIENCE:

Knowledge on SDLC.
Knowledge on OLAP.
Knowledge on Data Modeling concepts.
Knowledge on SQL, PL/SQL, Phyton or Java.
Knowledge on Snowflake or Oracle.
Knowledge on ETL / ELT, System Integration Process.
PERSONAL ATTRIBUTES:

Experience with testing tools, data warehousing.
Experience with Control-M BMC Scheduling tool.
Should have excellent attitude/skills with the business users.
Understanding of functional concepts & flow of Oracle Application Modules."
Avanade,Data Engineer,"What You'll Do

 Design, develop and configure software modules, interfaces and components
 Build the Data Ingestion framework and ingest data from source files to load into Staging layer
 Perform data profiling and identify any data quality issues and report to source systems
 Using best practices build the ETL components as per mapping rules to move data into ODS; SOR layer and Data marts"," 5-10 years of data analytics design and development experience
 Development knowledge of Python, Scala, HDFS Hadoop
 Understand Source data and support Source to Target mapping rules
 Proficient in ETL tools such as Azure Data Factory, Azure Databricks is required
 Good to have banking experience.
"
The Motley Fool,Data Engineer,"As a Freelance Data Engineer, you will be responsible for expanding and optimizing data, the

data pipeline architecture, the data flow, and collection for cross-functional teams. You are an

experienced data pipeline builder and data wrangler who enjoys optimizing data systems and

building them from the ground up. This role will involve collecting and integrating raw data from

various vendors, transforming it into clean, structured data sets, and building a scalable,

maintainable data mart. The ideal candidate will be responsible for ensuring the integrity and

usability of the data across downstream processes, working closely with stakeholders to ensure

data models align with business needs and support future growth. Strong technical skills and

Build data warehouses and data pipelines in Snowflake
Query and analyze large datasets in Snowflake using SQL
Debug and resolve data issues
Develop serverless data processing workflows using custom operators within Airflow.
Leverage data assets to meet mission needs, ensuring consistent data quality,
establishing data standards and governance

Work in an agile, collaborative environment, partnering with client stakeholders, to
develop and improve mission-based solutions

Monitor cloud-based systems and components for availability, performance, reliability,
security and efficiency

Create and configure appropriate cloud resources to meet the needs of the end users.
As needed, document topology, processes, and solution architecture.
Assist with the training and enablement of data consumers.
Share your passion for staying on top of tech trends, experimenting with and learning
new technologies","Enterprise-level data warehousing experience - specifically within Snowflake.
Proficiency in SQL, including multi-table joins, window functions, indexing strategies.
Data Debugging Experience
Experience developing using Python in context of data ingestion via REST APIs,
manipulation with native data types, and database connection

Experience with AWS Services, including Lambda functions, EC2/ECS instances, S3,
SQS, DynamoDB Tables; familiarity with IAM Roles and Policies.

Experience with development and deployment of data pipelines using Airflow; proficiency
in base and third-party operators for complex DAGs.

Experience with Snowflake setting up storage integrations, external stages, data shares,
snowpipes, RBAC; setting up tasks using Snowpark API.

Ability to work independently, and deliver results and drive projects with minimal
supervision

Strong ability to communicate blockers and issues to management for escalation and
timely resolution

Strong team player, with desire to learn new skills and broaden experience
Experience working with complex data sets
Nice to Have:

Experience with event tracking configuration in Google GA4 and analysis using
BigQuery

Experience with data migration project refactoring and optimizing complex SQL logic
Experience working with financial data
Experience investing and/or using The Motley Fool’s service offerings
Experience leveraging data quality tools to proactively address data discrepancies
Experience with DevOps, developing infrastructure-as-code via Terraform and/or
CloudFormation"
Token Metrics,Senior Crypto Data Engineer,"Liaising with coworkers and clients to elucidate the requirements for each task
 Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed
 Reformulating existing frameworks to optimize their functioning
 Testing such structures to ensure that they are fit for use
 Building a data pipeline from different data sources using different data types like API, CSV, JSON, etc
 Preparing raw data for manipulation by Data Scientists
 Implementing proper data validation and data reconciliation methodologies
 Ensuring that your work remains backed up and readily accessible to relevant coworkers
 Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs"," Bachelor's degree in Data Engineering, Big Data Analytics, Computer Engineering, or related field
 A Master's degree in a relevant field is an added advantage
 3+ years of Python, Java or any programming language development experience
 3+ years of SQL & No-SQL experience (Snowflake Cloud DW & MongoDB experience is a plus)
 3+ years of experience with schema design and dimensional data modeling
 Expert proficiency in SQL, NoSQL, Python, C++, Java, R
 Expert with building Data Lake, Data Warehouse or suitable equivalent
 Expert in AWS Cloud
 Excellent analytical and problem-solving skills
 A knack for independence and group work
 Capacity to successfully manage a pipeline of duties with minimal supervision"
Grab,Senior Data Engineer,"As a Senior Data Engineer, you will architect scalable data pipelines and systems. Your role involves close collaboration with multiple teams to ensure seamless data integration, processing, and delivery. You will enhance our data architecture with your expertise in big data technologies, focusing on reliability, scalability, and performance.

The Critical Tasks You Will Perform

You will develop scalable data pipelines and ETL (Extract, Transform, Load) processes, focusing on data extraction, transformation, and loading into our data warehouse.
You will collaborate with partners to gather and understand data requirements, translating them into technical solutions that align with our goals and reporting to the team Senior Engineering Manager
You will architect data models and schemas for efficient storage, retrieval, and analysis of structured and unstructured data.
You will implement best practices for data quality, governance, and security, ensuring the integrity of data assets.
You will optimize the performance and scalability of data infrastructure, using cloud services and distributed computing technologies.
You will implement new tools, frameworks, and technologies to enhance our data platform's capabilities.
You will mentor junior team members, offering guidance on technical design, coding standards.
You will stay current with industry trends and advancements in data engineering, contributing to continuous improvement and new ideas.","
Over 5 years of experience in data engineering with a ability to develop scalable systems.
Proficiency in programming languages such as Python or Scala and experience with data processing frameworks like Spark or Presto.
Hands-on experience with workflow management platforms such as Airflow.
Understanding of data formats like Avro, Parquet, Delta, ORC.
Knowledge of relational and NoSQL databases, data modeling, and SQL query optimization.
Familiarity with stream processing technologies such as Kafka or Flink.
For troubleshooting complex data issues.
Experience communicating updates and resolutions to customers and other partners to work with teams and convey technical information to non-technical partners."
UST,Data Analyst,"Job Description:

Data Collection and Management
-Gather data from various sources, including databases, spreadsheets, and external data sources.

-Clean and preprocess data to ensure accuracy and consistency.

-Manage and maintain data integrity and security.

Data Analysis
-Use statistical methods and tools to analyze data and identify trends, patterns, and insights.

-Conduct exploratory data analysis (EDA) to understand data characteristics and relationships.

-Perform data mining and build predictive models when required.

Reporting and Visualization
-Create reports, dashboards, and visualizations to present findings to stakeholders.

-Use tools like Power BI, or Excel to design and build interactive dashboards.

-Interpret and communicate complex data findings in a clear and actionable manner.

Collaboration and Communication
-Work closely with other teams such as marketing, finance, and product development to understand their data needs.

-Collaborate with data scientists and engineers to improve data collection and analysis processes.

-Provide data-driven recommendations and support decision-making processes.

-Strong attention to detail and ability to communicate complex ideas effectively.

Tool and Technology Utilization
-Utilize data analysis tools and programming languages such as SQL, advance excel, Power BI, Macros, Power Pivot, Power Query and VLoopUps.

-Work with databases and data management systems like SQL Server or MySQL.

-Stay updated with the latest data analysis technologies and methodologies."," A bachelor’s degree in a related field such as Data Science, Statistics, Computer Science, Mathematics, Economics or Accounting is typically required.
Advanced positions might require a master’s degree or relevant certifications (e.g., Certified Analytics Professional).
Relevant work experience or internships in data analysis or a related field can be advantageous.
Proficiency in data analysis tools and software (e.g., Advance Excel, SQL, Power Pivot, Power Query, VLookpUps)
Experience with data visualization tools (e.g.Power BI).
Knowledge of statistical methods and data modelling techniques.
Strong analytical and problem-solving abilities to interpret and analyse complex data sets.
Ability to identify patterns, correlations, and anomalies in data.
Excellent written and verbal communication skills to convey findings and insights to non-technical stakeholders.
Ability to create clear and concise reports and presentations."
UST,Data Engineer,"The individual will be responsible to provide ETL (extract-transfer-load) solutions and deployment of these solutions thus involve in various BI and Big Data Analytics related projects.
The individual will also be responsible in building necessary automation data feeds (ETL/ELT) mechanisms for data transfer from various source applications to target applications. Perform data integration - administration, optimization of performance evaluation & monitoring to the data feeds.
Support existing production portfolio and troubleshoot issues in providing fixes and solutions.
Participate in all aspects of software product development life cycle (SDLC) including requirement gathering, workflow architecture design, development, testing, demo, training and documentation. Plan, prepare and lead User Acceptance Test (UAT) for releases and ensure testing completeness.
The individual should demonstrate hi-energy and desire for data mining, scripting, problem solving and data analysis.
Work collaboratively with DBAs, infrastructure, network, data enablement teams and application BA analysts.
Collaborate improvements in data governance, methodologies and processes. Demonstrate a deep interest and understanding of big data, data modelling, data structures, data catalogue and how to manipulate data in an efficient manner. Quick in formulating quality, feasible and practical solution fit to big data application
Able to perform knowledge sharing of theoretical and practical.
Knack of exploring and try out new things related to Data Analytics world.
Training will be provided on needed basis.
","Someone with minimum 5 years of IT working experience especially into Business Intelligence or Data Analytics related job.
Possess at least a Degree in Computer Science, Information Technology, Engineering or related courses.
Data integration (ETL), mining, analytics experiences is A MUST. Experience in manipulating and analyzing complex, high-volume, high-dimensionality data from varying sources and perform ETL (extract transfer load) scripts.
Development experience in Data Lake solutions such as Data Bricks, Azure DataLake, Fabric, AWS, Snowflake, Cloudera or Data Fabric such as Atlan, cinchy, IBM for Big Data solution is preferred.
Have experience in development in Hadoop environment is an added advantage and understand components the applications in Hadoop eco-system using ETL framework components such as Nifi, Kafka, Pentaho, Spark, Datalake Insights etc.
Cloud environment development experience is preferred. HCIA/HCIP/HCIE certificate in cloud computing, or equivalent certificates in the industry preferred, ep: AWS, Azure, GCP cloud certificates. Familiarity with AWS particularly services S3, Lambda, EMR, EC2 is added advantage.
SQL experience a MUST. Perform SQL as daily routine job. Working experiences in development database (such as MSSQL Server, Teradata or Oracle).
Have working experience or exposure with Business Intelligence tools is highly recommended. Preferably: Tableau, Power Query, Power BI Desktop etc.
Coming from manufacturing background (but not essential).
Other preferred software skill(s): PHP, Python, Java, Javascript is an added advantage.
Strong visualization capability and passionate in quantitative analysis – statistics, math, modeling, design etc.
Strong written and verbal communication skills. Good communication background. Good command in English speaking, listening and writing is highly desired. Important as this needed to work will multi organization manufacturing and enterprise within the company
Must be result oriented with strong analytical, troubleshooting & problem-solving skills with minimal supervision.
Knowledge of Project Management and Safe Agile process is an added advantage.
Extremely passionate with data from source to end solution
Experienced working in a virtual team environment is a plus."
Apical,Sustainability Data Analyst,"
Lead, manage, and support corporate sustainability digital initiatives.
Analyze and centralise corporate sustainability data (energy, environment, finance, human resources, OSH, procurement, supplier etc.) for annual Sustainability Report publication.
Improve sustainability data collection tools and procedures.
Engage and advise operational data owners from different countries on data consolidation.
Enhance and assess current corporate sustainability performance.
Engage with consultants and designers on Sustainability Report publication.
Support sustainability reporting standards verification activities.
Prepare content and answer for external assessment (CDP, SPOTT etc).
Prepare data and required document for queries and questionnaires.
Provide support to other functional units (within same department).
Verify the compliance of ESG standards in suppliers’ site (ad hoc).","Diploma or certificate in Environmental Science, Sustainability, Business, IT or related disciplines.
At least 1-3 years of work experience will be preferred. 
Good computer literacy, especially MS Excel. Conversant in English.
Organized and meticulous, good sense of responsibility and willing to learn.
Positive and pleasant personality."
Portcast,Data Analyst,"Documentation, Reporting, Root Cause analysis of Prediction issues
 Analyze ingested and system-generated data for anomalies and gaps
 Refer to various data sources to plug those gaps
 Create data stories and come up with possible solutions in terms of QA process flow change and/or automation. Own the subsequent plan and execution
 Automation of Performance/Accuracy review processes, report generation, data visualization using Python, SQL
 Support engineering and data science teams in system-level data fixes. Understand how the engine makes predictions, explore possible improvements in the process by fixing/introducing new data/features
 Support the customer operations, marketing team in getting insights from the data, such as performance, accuracy metrics, impact of real-time events, etc. as required
 Maintain, own internal and customer dashboards based on the trial/account requirements (e.g. prediction accuracy, timeliness, coverage, explainability)"," Bachelor's or Master’s degree in Computer Science, Engineering, Information Technology, or a related field
 Prior experience in data analysis or data analyst roles, preferably in a startup environment
 Exceptionally skilled in Python and SQL, with a demonstrated ability to consistently produce reusable and highly scalable code
 An eye for detail: Looking for anomalies in the system
 Familiarity with Linux, GitHub, product development
 Proven experience with data visualization
 Empathy and Urgency: to feel the customer pain and react promptly on a day-to-day basis
 A Problem solver & go-getter: either programmatically or manually meeting customer expectations and delivering on time
 Fluent with written and verbal in English
 Strong ownership mindset, efficiency, and data-driven approach
 Good to have: basic understanding of machine learning algorithms"
Ant International,Risk Data Analyst,"Analyze diverse user and transaction data to identify risk characteristics.
Develop comprehensive user risk profiles and strategies for batch registration, fraud, and promotion abuse.
Create data-driven strategies to inform business risk decisions and support sustainable international operations.
Collaborate with teams in algorithms, policies, product development, and technology to enhance our AI-based merchant risk management platform.
Assist with departmental initiatives and additional duties as needed.","Bachelor’s degree in Mathematics, Statistics, Finance, Management Science, Computer Science, or related fields.
3-5 years of experience in big data analysis and data mining; experience in banks, payment institutions, card providers, or internet companies is preferred.
Strong analytical and problem-solving skills, with proficiency in SQL.
Collaborative and inquisitive mindset.
Proficient in English and Mandarin for effective communication with stakeholders.
Knowledge of SAS, Python, or R is a plus."
Hatfield Thistle,Data Analyst Admin,"Data Entry & Management: Accurately enter data into supply chain management systems, maintaining updated records of inventory levels, orders, and shipments.
Documentation: Prepare and maintain documents related to supply chain activities, including purchase orders, invoices, and delivery notes.
Record Keeping: Organize and archive supply chain records, ensuring they are easily accessible for reference.
Reporting: Generate regular reports on stores inventory status, ordering progress and performance for review by the supply chain team and management. Alerting the supply chain team of any discrepancies or low stock levels in-store.
Administrative Support: Provide general administrative support to the supply chain team.
Inventory Monitoring and Handling: Assist in monitoring inventory levels and handling inventory software.
Must possess excellent written and spoken English, Mandarin, and Malay communication skills. We are seeking candidates proficient in Mandarin to effectively communicate with Mandarin-speaking clients.","Education: Preferably a degree holder, administration, or a related field.
Experience: Preferably experience in an administrative role.
Technical Skills: Proficiency in Microsoft Office Suite (Excel, Word, Outlook).
Mathematical Proficiency: Sensitive with numbers and proficiency in mathematics.
Organizational Skills: Strong organizational and time management skills, with the ability to manage multiple tasks and priorities.
Communication Skills: Excellent written and verbal communication skills.
Attention to Detail: High level of accuracy and attention to detail in all tasks.
Problem-Solving Skills: Ability to identify issues, analyze problems, and develop solutions.
Able to speak in English, Bahasa Malaysia and Mandarin."
Funding Societies,Senior Data Analyst,"Collaborate with cross-functional and cross-regional stakeholders to understand business drivers, formulate and complete end-to-end analytics solution
Design, develop and maintain self-service reports, dashboards and analysis on interactive BI tools for easier data visualization 
Contribute in collection, processing and modelling of financial data using SQL from complex databases to integrate into data warehouse that can be used for reporting/analysis and to give recommendations and drive decision making 
Deliver effective presentations of findings and recommendations to different audiences, creating visual displays of quantitative information that drives financial decisions in the business 
Find innovative and creative ways to obtain and drill insights from new financial data ","Minimum 3 years experience in credit risk / risk management / data analytics
Passionate in analysing and interpreting data patterns to drive business decisions, understanding Data Warehousing and ETL would be a plus!
Highly proficient in SQL / Python and business intelligence tools (e.g. Tableau, Sisense, PowerBI)
Excellent communication, project management, and stakeholder management skills in order to collaborate confidently with decision makers across different regions and departments
CFA / FRM / Chartered Banker would be an added advantage"
BingX,Senior Risk Control Data Analyst,"Identify risks in market promotion and operational activities, pinpointing users with fraudulent behavior on a large scale
Collaborate with marketing, operations, and product teams to support promotional activities and integrate risk control strategies into tools
Analyze user behavior and feedback to uncover black market trends and fraudulent behavior patterns
Conduct data analysis of security cases and develop long-term solutions based on case studies
Generate analytical insights and work with relevant teams to optimize risk control strategies","Bachelor’s degree or higher in Computer Science, Statistics, Mathematics, or a related field from an accredited university
Over 3 years of data analysis experience, preferably in Internet finance and risk control
Proficiency in data analysis and statistical tools such as SQL, Hive, and Spark. 
Strong data sensitivity with excellent analytical and problem-solving skills Knowledge of A/B test design and causal inference is essential
Excellent communication skills with strong comprehension abilities, capable of effectively articulating complex data insights to various stakeholders.
Proficient in Chinese will be highly advantageous"
AirAsia,Lead Data Scientist,"Improve models and algorithms to further optimize business outcomes.
Collaborate and work across functional and multidisciplinary teams in a dynamic environment to develop an understanding of evolving/agile business needs.
","Requirements and Qualifications:

BS/MS/PhD in Science (Statistics, Management, Cognitive / Psychology, AI, Analytics, Marketing, Design, HCI).
Up to 10 yrs relevant experience beyond first degree.
Experience with common data science toolkits, programming languages, visualisation tools and SQL/NoSQL databases.
Good applied statistical knowledge with emphasis in business and finance related statistical distributions, statistical testing, modeling, regression analysis, etc.
Experience with distributed computing platforms and open-source tools and libraries.
Experience developing and deploying to the cloud.
Familiar or prone to adopt design thinking methods.
Able to work under pressure and change, and balance among speed, reliability, interpretability.
Good working knowledge of productivity tools such as G Suite, Git, Jira, Confluence.
Experience with code versioning, code review and documentation.
Ability to identify challenges. build relationships, and communicate across functions and geographies, and deliver successful solutions.
Strong problem solving skills with an emphasis on business solution product development.
Ability to mentor junior data scientists.


Experience in one or more of the following specialized areas:



Machine Learning

Understanding of machine learning algorithms such as k-NN, Naive Bayes, SVM, Decision trees.
Experience using ML frameworks such as TensorFlow, PyTorch, or scikit-learn.
Experience with Google Cloud Platform products and services such as Vision API, Recommendations API, Cloud Natural Language.
An in depth knowledge of AI techniques, their real-world advantages/drawbacks, and ability to prescribe and implement feasible and appropriate conventional/AI related techniques that serve as solutions to problems.
Design, implement, and analyze A/B tests to optimize product features, marketing strategies, and customer experiences.


Algorithm Engineering

Strong ability to implement, improve, and deploy ML and Math models in Golang or Python.
Conduct systems tests for security, performance, and availability.
Develop and maintain the design and troubleshooting/error documentation.
Create cost effective scalable systems and develop innovative algorithm solutions.
Research on algorithm improvements for higher performance, accuracy, and optimality.


Operations Research

Familiar with modelling problems as mathematical programming, constraint satisfaction, particle swarm optimization and other appropriate OR methodologies.
Familiar with tools such as Cplex, Gurobi, Google OR-Tools.
Knowledge of advanced statistical and Operations Research techniques and concepts and experience with applications development.


Decision intelligence

Drive decision science aspects as a standard user experience -staff or customer- process (cognitive biases, cross-cultural reasoning, statistical interpretation, human factor impact, algorithmic bias etc.).
Actively showcase the added value of design thinking, data-driven decisions, agile and user-centric methods.
Support research (user and markets) and data processes for enhanced decision quality.
Develop strategic action plans integrating human factors and data science to improve AI driven decisions and choice architecture (persuasive design)."
Moneylion,Senior Data Scientist,"Perform analyses to understand how our users interact with our products and how to improve our products
Communicate findings to stakeholders in a clear and concise manner
Automate Identification of anomalies and investigate the root causes of anomalies
Lead, design and build experiments to solve challenging data and business problems
Identify trends and opportunities from the data to define product roadmaps
Craft business metrics, define and achieve objective targets and recommend ways to measure success
Work with engineers to improve the data collection process
Collaborate with product stakeholders to champion and lead data-driven decision making within the organization
Apply, develop or refine algorithms to deliver business value
Research, adopt and implement novel and cutting-edge techniques from literature to improve the performance of existing solutions
Mentor, coach, and manage team members towards excellence in deliverables","3-5 years of working experience minimum recommended
Experience with mentoring, training, hiring, onboarding, managing or leading a team will be advantageous
Have strong product sense and enthusiastic to deliver business value 
Strong mathematical, statistical or actuarial background
Must have hands on experience in machine learning, predictive analytics and statistical modeling
Deep knowledge of probability, statistics, distributions, and analysis methods
Demonstrably experienced at problem solving using both textbook methods and novel viewpoints
Highly proficient in programming languages such as Python and SQL
An understanding of data structures, data modeling, software architecture and machine learning algorithms will be an advantage
Demonstrably experienced with data visualization
Demonstrably excellent verbal and written communication skills
Highly independent and self driven to deliver results "
Webqlo,Senior Data Scientist,"Writing modular, well-tested, and maintainable code.
Manipulating large volumes of data pre-processing that involves data transformation and data cleaning. 
Researching, measuring, and analysing what works and what doesn’t. 
Exploring new technologies and analytics solutions, and using depths of knowledge in statistics and various machine learning tools to forecast and classify patterns in the data.
Increasing performance and accuracy of machine learning algorithms through fine-tuning and further performance optimisation.
Liaising and working closely with team and clients to clearly define and establish the requirements for each task.
Working closely with stakeholders to Identify opportunities for leveraging data to propose solutions for effective decision making.
","At least 3 years of experience as a Data Engineer or Data Analyst. 
3 years of experience in Python. Knowledge of Hadoop, Spark, and other ML tools will be of added value. 
Experienced in Shell Script, Linux Configuration, MySQL, and NoSQL. Knowledge of AWS S3, FTP, and Microsoft SQL will be of added value. 
Strong math skills in statistics, algebra, regression, etc. 
Able to work under minimal supervision.
Strong organisational and project management skills.
Collaborative team player.
Passionate and possesses good problem-solving skills.
Good verbal communication skills.
Good attention to detail to ensure data quality and integrity is upheld. 
Guide and support a team of juniors. 
Initiative to share knowledge, experience, and ideas at work. "
SEEK,Data Analyst,"Responsible for building, maintaining and improving dashboards for performance health monitoring and tracking effectiveness of initiatives for teams
Work with Product Owners/ Partners to define objectives and important metrics for streams and projects
Define and prepare measurement specifications and implementation requirements for projects across all platforms (desktop, mobile, email, etc)
Deliver accurate and value-adding useful insights of user behaviour
Provide pre and post-launch reviews of initiatives/ experiments
Communicate clear data, analysis and useful insights to enable partners in making informed decisions
Independently handle data queries from partners","At least 3-5 years’ experience working in analysis, strategy or research-related roles
An important plus point if having 2-3 years of experience with at least one of the web/ digital analytics tools like Google Analytics, Google Search Console, Adobe Analytics, Power BI or Tableau
Strong analytical skills and critical thinking skills
Strong foundation with statistical knowledge, practices and application in business
Strong collaborator to build and maintain relationships with Data teams, partners and peers
Involved in developing and managing strategy or research projects and defining these in terms of specific objective and business desired outcomes
Ability to motivate and lead internal/ external teams to deliver results beyond expectations.
Ability to work in a fast-paced global business environment and manage partners’ expectations across different time zones"
Software International Sdn Bhd,Data Engineer,"Participate in custom enterprise application development and maintenance for large corporations both within Asia and worldwide.
Provide solutions to the business users.
Design, code constructions, SIT testing, support UAT and implement enhancements.
Develop the necessary documentations (technical specs, test plan, change management) to support the IT SDLC process.
Provide level-2 BAU (production support) eg. batch runs, OS patching/upgrade, tech refresh/upgrade.
Work with infrastructure team to ensure applications are smooth running.","At least 3 years with hands-on experience:
Database – DB2 (Preferred), Oracle (Preferred), IBM Netezza
ETL/ELT data workflows – Data Stage (Preferred), SAP BI
Data warehouse, Data mart – including analysis of business/users requirements, solutioning
Data design and data model
Possess strong analysis abilities with acute sense of data analytics.
Multiple years of experience in a professional environment performing analysis, design and development tasks on multiple platforms.
Familiar with data analytics, data mining concepts and machine learning algorithms.
Proficient in data design, data architecture, robust ETL/ELT data workflows."
Fairview International School,Junior Data Analyst,"Develop sophisticated demand projection models to anticipate enrollment trends and simulate the impact of policy changes. Conduct in-depth data analysis to uncover underlying patterns and drivers of key trends. Utilise geospatial analysis to identify underserved areas and inform targeted recruitment and outreach efforts with the marketing team.

Evaluate the effectiveness of existing policies and programs through rigorous data analysis. Ensure data accuracy and integrity by performing thorough data validation and cleansing processes. Transform complex data into clear and compelling visualisations, reports, and presentations for stakeholders.

Collaborate closely with the academic team and stakeholders to communicate findings and recommendations effectively. Streamline data management processes and improve overall data documentation. Leverage data mining and machine learning techniques to design surveys and extract valuable insights for the academic team.

Assess the effectiveness of research instruments in-relation-to academic data.","Bachelor's degree in data analytics, statistics, mathematics, computer science, or a related field.

Proven experience in data analysis, modelling, and visualization. Proficiency in statistical software (e.g., SPSS, R, Python, SQL) and data visualisation tools (e.g., Tableau, Power BI). Knowledge of Google App Script is a bonus for data automation and report generation.

Understanding of data mining and machine learning techniques. Excellent problem-solving and critical-thinking skills. Strong communication and presentation skills.

Ability to work independently and collaboratively within a team"
Encora Inc,Data Engineer,"Analyze and organize raw data 
Build data systems and pipelines
Evaluate business needs and objectives
Interpret trends and patterns
Conduct complex data analysis and report on results 
Prepare data for prescriptive and predictive modeling
Build algorithms and prototypes
Combine raw information from different sources
Explore ways to enhance data quality and reliability
Identify opportunities for data acquisition
Develop analytical tools and programs
Collaborate with data scientists and architects on several projects","Experience: 3- 8 years

Proficiency in Oracle PL/SQL and MS SQL.
Experience with data replication, change data capture, and performance tuning.
Familiarity with data warehousing concepts and ETL processes.
(Good to have) Knowledge of Kafka and Debezium.
"
FootfallCam,ML Engineer,"Design, develop, and deploy machine learning models and algorithms for complex and unique datasets, using various techniques such as mathematical modeling, scikit-learn, NLP, CNN, RNN, DL, RL, Transformers, GAN, LLM, RAG, prompt engineering, GPT.
Collaborate with cross-functional teams to extract insights, identify business opportunities and provide data-driven recommendations
Stay up-to-date with the latest machine learning and AI techniques and tools
Communicate complex technical concepts to non-technical stakeholders in an easy-to-understand manner","Bachelor's degree or higher in Computer Science, Mathematics, Statistics, Actuarial Science, Informatics, Information Science or related fields
Strong analytical skills and attention to detail
Participation in Kaggle, Mathematics Olympiad or similar competitions is a plus
Excellent programming skills in Python, R, Java, or C++
Familiar with ML frameworks such as Tensorflow, Keras, PyTorch, MLFlow, AutoML, TensorRT, CUDA
Excellent communication and collaboration skills
Experience with designing, training, and deploying machine learning models
Customer centric and committed to deliver the best AI results to customers"
Capital Dynamics,Data Scientist,"Researching and analysing market trends using quantitative model and using technical analysis to make trading decisions
Developing and implementing complex quantitative models (e.g. trading & forecasting)
Performing daily statistical analyses (e.g. risk analytics and default risk modelling) and coding tasks (e.g. pattern recognition or machine learning)
Detailing model specifications and methods of data collection
Testing new models, products and analytics programs
Developing optimal strategies
Developing new data algorithm and models to support company products
Presenting and interpreting data results to senior management and clients","Strong problem solving skill.
Preferably with a minimum of 2 years’ experience in data science related roles.
A solid Bachelor's degree in Computer Science or Mathematics or Statistics or any other related computational discipline from a reputable university. Applicants with the relevant master's qualification would have an advantage.
Proven expertise in data science and analytics for key areas, such as probability and statistics, time-series analysis, pattern recognition, optimisation, and predictive modelling.
Understanding supervised and unsupervised machine learning techniques and algorithms, such as k-Means, SVM, Decision Trees, Random Forest, etc. is a plus.
Hands on programming experience in Python and R.
Excellent written and verbal communication skills for coordinating across teams.
A drive to learn and master new technologies and techniques.
Good command of spoken and written English."
Accord Innovations,Data Engineer,"Create and maintain optimal data pipeline architecture as per best practices.
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and ‘big data’ technologies.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and Azure regions.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems.
Design and develop enterprise and departmental business intelligence, data warehousing and reporting solutions.
Assist in defining strategies and executing tasks and projects.
Develop and implement reports and queries to drive business processes.
Ensure business users have proper authorities to reports and data.
Provide technical and business knowledge support to the team.
Ensure effective communication of user requirements.","Data Engineer more than 5 years of experience in building pipelines,
Data Support Engineer: 3 to 5 years in building or supporting pipeline and ensuring data quality on a day-to-day basis
They should also have experience using the following software/tools:
Experience with big data tools: Hadoop, Spark, Kafka, Big Query, etc.
Experience with relational SQL and NoSQL databases, including Postgres / Cassandra/ MongoDb/Cosmos Db.
Experience with data pipeline and workflow management tools: Airflow, Azure Data Factory, Databrick, AWS Glue, Snowflake, Azkaban, Luigi etc.
Experience with stream-processing systems: Storm, Spark-Streaming, Kafka etc.
Flexible and able to take up new role and responsibility as per company’s direction.
Nice To Have
• Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
• Experience building and optimizing ‘big data’ data pipelines, architectures and data sets.
• Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
• Strong analytic skills related to working with unstructured datasets.
• Build processes supporting data transformation, data structures, metadata, dependency and workload management.
• A successful history of manipulating, processing and extracting value from large disconnected datasets.
• Working knowledge of message queuing, stream processing, and highly scalable ‘big data’ data stores.
• Strong project management and organizational skills.
• Experience supporting and working with cross-functional teams in a dynamic environment."
Accord Innovations,Data Scientist," Understand business requirements in BI context and design data models to transform raw data into
meaningful insights
• Create dashboards and interactive visual reports using PowerBI or equivalent
• Identify key performance indicators (KPIs) with clear objectives and consistently monitor those
• Analyzing data and presenting data through reports that aid decision-making
• Convert business requirements into technical specifications and decide timeline to accomplish
• Create relationships between data and develop tabular and other multidimensional data models
• Chart creation and data documentation explaining algorithms, parameters, models, and relations
• Design, develop, test, and deploy Power BI scripts and perform detailed analytics
• Perform DAX like queries and functions in the BI tool
• Analyze current ETL process, define and design new systems
• Data warehouse development and work with ADF , SSAS, SSIS, and SSRS
• Redefine and make technical/strategic changes to enhance existing Business Intelligence systems
• Create customize charts and custom calculations as per requirements
• Design, develop and deploy business intelligence solutions as per needs
• SQL querying for best results, use of filters and graphs for better understanding of data
• Work with users and team members at all levels for performance improvement and suggestions
• Make technical changes to existing BI systems to enhance their working.
• Comply with the instructions of the Scrum Master in creation and updates of tasks and activities
• Work with Scrum Master and senior developers in estimating the effort for tasks and activities
• Update status and remaining hours for tasks and activities on daily basis, as per instructions from Scrum Master","Qualifications
• Bachelor’s degree in Computer Science, Computer Information Systems, Computer
Engineering, or equivalent.

 Must Have
• Five years demonstrated experience in utilizing related skills, including experience with
existing standard languages and programs.
• Demonstrated experience writing optimized SQL queries.
• BI tools: Skills in BI tools and BI systems, such as Power BI/SAP / Tableau / Chartio /Apache SuperSet /
Looker /Google Data Studio or equivalent, etc., creating data-rich dashboards, implementing Row-level
Security (RLS) in Power BI, writing DAX expressions, developing custom BI products with scripting and
programming languages such as R, Python, etc.
• Microsoft BI stack: In-depth understanding and experience with Microsoft BI stacks such as
Power Pivot, SSIS, SSRS, and SSAS.
• Able to understand and communicate effectively in English
• Flexible and able to take up new roles and responsibility as per company’s direction

Nice To Have
• Relevant experience with some of these: Power Apps, Power Automate, JavaScript, JSON,
TypeScript, C#, HTML, .NET, Azure, Microsoft 365, RESTful web services, ASP.NET
• Previous experience with database management preferred.
• Experience with conceptual software development, on-line survey development, user
interface design, statistics and graphics programming, and data processing huge plus.
• Knowledge of SQL and PLSQL scripting languages.
• Knowledge of programming languages like Python.
• Experience in ETL pipeline ADF /Apache Airflow/ AWS Glue or equivalent
• Knowledge of data streaming principles, data modeling, and data visualization."
DKSH,Senior Data Governance Business Analyst,"Participate in the development of Data Governance strategies, implementation roadmap and deliver solutions for business cases.
In collaboration with Business Data Steward and IT Functional and Application Team, help to define, establish and maintain Global Data Policy or Standard Operating Procedure for different data domain such as Customer, Vendor, Material and other’s critical data set.
As Master Data Maintenance Tool Application Owner: 
- Troubleshoot & resolve users MDM application/technical issues in a timely manner according to service level agreements and objectives. Escalate & collaborate with relevant IT delivery teams as necessary to resolve complex issues.
As Master Data Business Analyst:
- Conduct business requirements studies and manage design discussions between business users and technical teams. Translate business requirements into technical requirements for the technical delivery teams. 
- Prepare test scripts, define, and document test scenario as required.
- Manage and conduct User Acceptance testing and obtain required signoffs. 
- Prepare training material, user guide documentation and conduct user training.
Project Management: 
- Lead Data Governance projects end-to-end, defining project approach, timeline and resources planning, coordinate with stakeholders at global and country level to complete delivery on time & with quality. 
- Create and maintain project documentation according to DKSH project management requirements.
- Responsible for engagement & collaboration with business users at global, regional & country level and the management of business stakeholders’ expectations.","Education

A Bachelor’s Degree in IT/Science/Computing/Engineering/Data management or equivalent education and work experience.
 

Work Experience

Minimum 3 years total working experience in SAP ERP or Master Data/IT ERP Applications/IT Application Project implementation. 
Minimum 3 years professional experience with SAP ERP Functional Modules ie: Customer, Vendor, Material Master Data is required; module structure, tables & fields relationship, Master Data maintenance process.
Good working knowledge of one or more Business Process areas such as Sales & Marketing or Supply Chain Management.
 

Good to Have

Minimum 3 years professional experience with SAP ERP Functional Modules ie: SD/MM/FICO is required; module structure, tables & fields relationship.
Minimum 3-5 years professional experience with SAP ERP Functional Modules ie: S/4HANA Business Partner, Vendor Master Data, Material Master Data; module structure, tables & fields relationship, Master Data maintenance process."
XSolla KL,Data Analyst,"Create visually appealing and informative reports tailored to specific stakeholder needs. This involves selecting the right metrics, visualizations, and layouts that effectively communicate insights.
Establish a routine for updating reports and dashboards to ensure they reflect the latest data. This includes scheduling automated data refreshes and revising reports as business needs change.
Develop and enforce data entry standards and protocols to ensure consistency across all data sources, reducing discrepancies and confusion.
Maintain comprehensive documentation of data sources, transformations, and methodologies to ensure transparency and reproducibility, making it easier for teams to understand the data lifecycle.
Work on collaborative projects that require input from multiple teams, fostering a data-driven culture and ensuring that analyses are comprehensive and relevant.
Develop customized analytical solutions that align with departmental goals, providing specific insights or tools that facilitate decision-making.",
Astro,Data Analyst,"Own the customer and product data and how it can be analysed, modelled and transformed to provide internal stakeholders with insight and information needed to drive business models. 

Work with a wide range of business stakeholders and functional teams to discover solutions/insights hidden in large data sets.

Answer requests from business users of data for insight and reports to extract commercial value from data. 

Extract, clean, and transform data to generate insights and reports for business stakeholders on an ad hoc or project basis. 

Prioritise and apply rigorous analysis to deliver insights: Viewership behaviours and pattern, customer acquisition and retention rates, user content consumption and navigational patterns. 

Conceptualise, create and deploy dashboards to track websites and mobile apps performance for reporting purposes 

Investigate data issues affecting analysis or ad hoc requests and implement necessary changes. 

Work closely with data scientists to develop analytical products to improve insights. ","Key skill sets:  

Strong problem solving skills  and analytical acumen to interpret and generate insights.  

Experience in using statistical computer languages (Python, SQL, PySpark, etc.) to manipulate data and draw insights from large data sets. 

Experience querying from databases.

Experience in visualizing/presenting data for stakeholders using tools like Tableau/QuickSight/PowerBI/ Looker Studio 

Familiarity with Google Analytics 360 for business requirements.  

We’re looking for someone with 2-5 years of hands-on experience in data and generating insights for varied business stakeholders.  "
Mandrill Tech,Data Engineer,"Assembling large, complex sets of data that meet non-functional and functional business requirements
Identifying, designing and implementing internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes
Building required infrastructure for optimal extraction, transformation and loading of data from various data sources using AWS and SQL technologies
Building analytical tools to utilize the data pipeline, providing actionable insight into key business performance metrics including operational efficiency and customer acquisition
Working with stakeholders including data, design, product and executive teams and assisting them with data-related technical issues","Ability to build and optimize data sets, ‘big data’ data pipelines and architectures 
Ability to perform root cause analysis on external and internal processes and data to identify opportunities for improvement and answer questions 
Excellent analytic skills associated with working on unstructured datasets 
Ability to build processes that support data transformation, workload management, data structures, dependency and metadata.
Proficiency in Python programming and SQL.
Experience in implementing data storage solutions (data warehouse / data lakes)
Experience with database management systems (e.g., MySQL, PostgreSQL).
Familiarity with data integration and ETL tools (Talend, Airflow, MageAI) is a plus.
Knowledge of Docker is a plus.
Hands-on experience with Tableau is preferred.
Excellent communication skills and the ability to work collaboratively with cross-functional teams."
bp,Senior Data Analyst,"Be a bridge between the broader bp business and the digital organizations and part of a cross-disciplinary team, working closely with our team of analysts, product managers, data scientists, data engineers, software engineers, data managers and business partners.
Provide actionable, data-driven business and product insights by combining deep statistical skills, data manipulation capabilities and business acumen.
Maintain metrics and build dashboards.
Autonomously execute data analysis, applying existing data & analytics strategies relevant to your immediate scope
Partner with data engineers to define and build simple data models. You integrate existing tools to automate data ingestion, data manipulation, quality control and data analysis.","Hands-on experience (typically approx 5-7 years) carrying out data analytics, data mining and product analytics in complex, fast-paced environments.
Applied knowledge of data analytics and data pipelining tools and approaches across all data lifecycle stages.
Deep understanding of a few and a high-level understanding of several commonly available statistics approaches
Advanced SQL knowledge
Advanced scripting experience in R or python.
Ability to write and maintain moderately complex data pipelines
Strong communication and stakeholder management skills. Ability to lead large organizations through influence.
Continuous learning and improvement mindset."
Capgemini,Senior Data Analyst,"Lead and mentor a team of data scientists in developing and implementing advanced analytics solutions.
Collaborate with business stakeholders to understand their requirements and translate them into data science projects.
Design and implement machine learning models and algorithms to analyze large-scale datasets, utilizing Python (including XGBoost, LightGBM, NLTK, Spacy, Pyspark, Tensorflow, networkx), Dataiku, and SAS.
Apply business acumen, particularly in the banking domain, to develop data-driven insights and solutions.
Demonstrate leadership skills and stakeholder management to effectively communicate findings and drive decision-making.
Conduct statistical analysis and hypothesis testing to derive actionable insights from data.
Develop data pipelines and workflows for data processing and model deployment.
Stay updated with the latest trends and best practices in data science and machine learning.",
Mintel Consulting,Trends Analyst,"Researching market innovations: as a Trends Analyst covering the Americas, this role will be tasked with finding interesting examples of product and marketing innovation in North and South America, sourced from news articles, trade publications, academic journals and other secondary sources.
Writing case studies: the primary job function will be writing thought-provoking case studies that highlight the implications of brand actions such as bringing new products to market, launching marketing and PR campaigns, or changing business strategies. These case studies require the Trends Analyst to use Mintel data, business understanding and a bold, forward-looking perspective to help readers recognize what is coming next in their category.
Working with tech tools: using AI tools, translation software and content management systems, the Content Specialist will manage the production process from inception to publication.
Collaborating with global analysts: this role will include partnering with Mintel subject-matter experts across the globe to ensure our content is compelling, useful and applicable to a range of categories, demographics and regions.
Managing culture and language translation: to cover the Americas region, this Trends Analyst will need to understand the cultural nuances of North and South America and use translation tools to read and interpret market news from Spanish, Portuguese and English language outlets.","A Great Communicator: you have extremely polished English-language verbal and written communication skills, and can clearly communicate ideas to readers in a straightforward way. You have a keen ability to explain and promote analytical output to non-technicians.
A Researcher: you have some experience within trends, insights, planning or marketing within an agency or on the client side. You have the ability to identify patterns in data, and understand what these patterns mean for consumers and brands.
A Skilled Writer: you are able to observe brand and consumer activity from a wide range of categories to create compelling stories of how broader consumer trends are evolving. You can create content that excites and inspires audiences with the latest trend thinking.
A Collaborator: you encourage and develop internal relationships. You seek out opportunities to collaborate with peers in your department and across the organization to ultimately elevate our clients' experience.
Detail-Oriented: you have excellent attention to detail and strong organizational skills. You are dedicated to quality, ensuring accuracy and efficiency in your work to elevate Mintel as a top consumer insights company.
Naturally Curious: you are naturally curious and great at navigating internal and external data, asking second and third level questions to see the patterns behind data to craft expert analysis.
Self-Directed: you take initiative to solve problems and uncover opportunities. You have a self-sufficient work ethic, are entrepreneurial in spirit, and are naturally self-motivated. You welcome the ability to work autonomously and bring new ideas to the table.
Experience: You are required to have 1-3 years of experience in marketing, communication, data analysis and/or research with strong writing ability. Additionally, to have a working knowledge of business fundamentals to understand the implications of brand tactics.
Copywriting experience would be an added plus. "
Orsted Malaysia,Master Data Analyst,"You’ll play an important role in:

in the creation, maintenance, and validation of master data
central checks and controls
taking care of data enhancements and data correctness
support end users
clarify request content with business users and business partners.","To succeed in the role, you:

have a bachelor’s degree in business administration, accounting, finance, or a member of any professional bodies
strong attention to detail and organizational skills
have an analytical and logical approach to issues and problem-solving
excellent communication skills, both written and verbal
basic understanding of data management principles and best practices"
PwC Malaysia,Senior Data Scientist,"Analyze large and complex datasets to identify patterns and trends using statistical techniques to derive actionable insights.
Develop, test, and validate predictive and descriptive models to support business objectives. Apply machine learning algorithms and statistical methods to solve real-world problems.
Create clear and compelling visualizations to communicate findings and insights to stakeholders.
Clean, preprocess, and transform data from various sources to ensure accuracy and usability for analysis and modeling.
Generate and present reports that summarize analytical findings and recommendations. Provide actionable insights to guide strategic decision-making.
Stay abreast of the latest trends and advancements in data science, machine learning, and analytics. Propose and implement innovative techniques and methodologies to enhance data practices.
Maintain thorough documentation of data science processes, models, and methodologies to ensure transparency and reproducibility.","Bachelor’s Degree in Data Science, Computer Science, Statistics, Mathematics, or a similar field.
Minimum 2-3 years of experience as a Data Scientist or in a similar role, with a proven track record of applying data science techniques to drive business outcomes.
Proficient in data analysis and visualization tools (e.g., Python, R, SQL, Tableau, Power BI). Experience with machine learning libraries and frameworks (e.g., TensorFlow, PyTorch).
Proficient in cloud platforms (e.g. AWS Sagemaker, AWS Quicksight, Azure Machine Learning).
Experience with deep learning techniques and natural language processing (NLP).
Excellent analytical and problem-solving skills with the ability to tackle complex data challenges and derive actionable insights.
Strong verbal and written communication skills, with the ability to present complex findings in a clear and concise manner.
Knowledge of data privacy and security best practices."
DCap Digital,Data Scientist,"Data Science and Credit Scoring (≈50%):

Assist in developing and maintaining alternative credit scoring models using machine learning techniques and non-traditional data sources.
Analyze diverse datasets, including non-traditional data, to identify patterns and trends in credit risk for underserved populations.
Support risk management teams in implementing credit assessment strategies.
Create data visualizations and reports to communicate insights to stakeholders.
Contribute to improving model performance through testing and validation.
Respond to ad hoc data analysis requests from various departments, providing quick insights and solutions.
AI Application Development (≈50%):

Participate in designing and developing AI applications to enhance various business processes.
Assist in implementing natural language processing (NLP) and computer vision solutions.
Contribute to the creation and optimization of deep learning models for predictive analytics.
Help develop AI-driven chatbots and virtual assistants to improve customer service.
Collaborate with software engineering teams to integrate AI solutions into existing systems.
Address urgent AI-related queries and provide rapid prototypes or proof-of-concepts as needed.","Malaysia citizen with Bachelor's or Master's in Data Science, Computer Science, Statistics, or a related field.
1 to 3 years of experience in data science, with exposure to credit risk modeling and/or AI applications development.
Strong programming skills in Python and SQL.
Proficiency with machine learning libraries (e.g., PyTorch, scikit-learn, or equivalent).
Knowledge of cloud platforms (e.g, AWS) and containerization (Docker) is advantageous.
Good communication skills and ability to explain technical concepts to non-technical stakeholders.
Strong problem-solving skills and attention to detail.
Flexibility and adaptability to manage multiple projects and ad hoc requests simultaneously.
Ability to work effectively under pressure and meet tight deadlines."
Boostorder,Data Analyst Intern,"To be well-versed in Boostorder's data environment
Utilize BI tools effectively to translate and deploy Boostorder's Standard Business Intelligence (BI)
Deliver description, prescriptive, and predictive insights to Boostorder's ecosystem
Pilot with customer data to create AI/ML model to enable prescriptive analytics and quantify customer success via these models
Lead and develop prescriptive data models and productize them as standard Boostorder's offering","Must-have:

Bachelor's Degree in Computer Science, Mathematics / Statistics, Actuarial Science
Experience in data visualization dashboard development and maintenance
Design and maintain database of at least 1 million rows in data set
Experience in SQL databases
Experience in visualization tools (Power BI or Tableau)
Building API connectors and performing ETL
Great to have:

Master and PhD in Computer Science, Mathematics / Statistics, Actuarial Science
Business / Finance / Marketing background
Practical experience in statistical analysis (Excel, SPSS, and SAS)
Experience with AI / ML models either through supervised, unsupervised, reinforced or deep learning"
Publicis Groupe,Data Analyst,"Digitas is a highly-caffeinated playground where brilliant minds come together to bring bold, award-winning ideas to life.

The Data & Analysis team uses data-driven insights to fuel strategic growth for clients. We believe that data should never exist in a vacuum; instead, it should be put to work to bring the best ideas and stories to our clients.

To help with this, we are looking for an outstanding Data Analyst – someone who has a knack for understanding data and telling the story of why it matters. You will learn from the best in the business as you work with the team to bring actionable insights to our clients. Up for it? Read on.

What you will do:

As an Analyst, you will participate in laying the groundwork and contribute to day-to-day reporting needs for client marketing efforts. You will be assigned to primarily social and web analytics projects and reporting for a client brand.


Day-to-day, your role includes:

Keeping a pulse on daily, weekly and monthly performance data from analytics platforms
Working in a variety of reporting systems and databases for the creation of recurring reports and dashboards
Participating in brainstorms to identify nuances in data to optimize our clients’ business
Supporting marketing initiatives across project and campaign lifecycles, including measurement plans, primary and secondary research and performance reporting
Expanding industry knowledge and relevant skillsets through scheduled internal training
Participating in ad hoc requests from accounts handled such as root-cause analysis, reporting, data insights generation and more.","Familiarity with different social media ecosystems, trends and tools (Meta, Instagram, TikTok, Snapchat, blogsites and more)
Analyzing social media performance, monitoring brand mentions, identifying trends to inform social media strategy
Understanding and familiarity with social analytics tools (Meltwater, Sprinklr, Netbase etc.)
Defining keyword taxonomy and query setup in social listening tool per client requirements
Experience in building widgets and dashboards within social listening tools
Familiarity with Excel or any scripting languages for additional data analysis
Comfortable in a fast-paced and deadline-driven environment
Able to prioritise tasks and provide timely updates
Team player, Independent & Detail-oriented
Ability to learn and adapt to different systems and various database
Passion for digital marketing, eagerness to learn in a constantly-changing industry, and possess natural curiosity
1-3 years of work experience in a relevant industry
An undergraduate college degree
Proficient in English & Bahasa Malaysia. Mandarin is a plus."
Hilti,Data Engineer Intern,"In the role of a Data Engineer Intern at Hilti you will be exposed to latest data engineering technology, work closely with leading experts in the field and will be embedded into the truly global environment of an international company. As part of the enterprise data platform team, you guarantee the seamless, timely and well managed provisioning of data from all data domains to all data domains in the company. The role will require you to fully understand dataflows in the broadest sense possible, dealing on a day-to-day basis with sales, development and IoT data alike, from the source system up until frontend solutions. Working closely together with senior team members you will act as the key technical enabler of data access and orchestration, guiding business stakeholders of all levels on their data requirements journey.

You support hands-on and – depending on your previous experience – work autonomously to retrieve, process and store large sets of data. You work closely with other data engineers and data scientists to understand and act upon data provisioning requirements. You deal with high level of technical complexity and understand integration patterns across various technical platforms, ranging from cloud based large data processing tools and frontend solutions alike. You are encouraged to ideate and test your own solution designs and are supported if explore unconventional approaches.","You study Computer Science, Engineering (Computer/Telecommunication) or any related quantitative field with a prospect to complete in the near to mid-term future and excellent grades.
You have a passion for mathematics and data as well as software engineering. You feel confident with basic software engineering skills (software architecture, version control systems, continuous integration software).
You understand concepts of distributed computing frameworks and big data and had touchpoints with object-oriented coding, Hadoop, MapReduce, HDFS, etc.
Strong programming skills (Python, Spark, SQL).
Strong communication skills, with excellent English and interpersonal skills to manage change.
A strategic approach and good problem-solving skills.
As a strong team player, you can work in a diverse and dynamic global environment.
A thirst to learn and challenge yourself.
Experience with cloud based hyper scaler (AWS, Azure) is preferred for this position."
KK Group,Data Engineer Lead,"Data Management, Transfer and Preparation

1) Making large and/or complex data more accessible, understandable and usable

2) Transforming, improving and integrating data, depending on the business requirements

3) Delivering the data in a useful and appealing way to users

4) Work with noisy, dirty, and unstructured data, data cleansing, scraping unstructured data, and converting into structured data

5) Build and maintain data pipelines, ETL, databases and applications to acquire, store and manage data

6) Choose, design, test and implement data software and solutions for projects and enterprise

7) Selecting and integrating any Big Data tools and frameworks required to provide requested capabilities

8) Monitoring performance and advising necessary infrastructure changes to optimize performance and cost

9) Architect, develop and implement end-to-end automated data flows for data and analytical needs

10) Perform data profiling, data quality assessment, data cleansing and data transformation

11) Recommend appropriate solutions architecture that is highly scalable based on business requirement

12) Create date tools for data scientists and data visualization team members

13) Builds the infrastructure required for optimal extraction, transformation, and loading for data from a wide variety of data sources using SQL, noSQL and cloud (AWS / Azure / Google / Alibaba / DigitalOcean) technologies

14) Benchmark, evaluate and improve the scalability, robustness, efficiency and performance of big data platforms and applications

Create Business value through data management, transfer and preparation

1) Engage in the delivery of analytics assignments for business users involving, amongst others; data preparation, data visualization, creating business insights etc

2) Contribute and facilitate workshops/interviews bridging the gap between data analytics and business outcomes

3) Provide strategic and tactical advice to business units by translating analytical solutions into out-of-the-box execution recommendations addressing business objectives and impacting bottom line results

4) Combine your technical expertise with the ability to architect, deploy and oversee integrated analytics/business intelligence/technology solutions

5) Build case for analytics through need analysis and business case (quantify likely benefits)

Team Lead

1) Consult with leaders of business teams and manage expectations, meet project and deliverable timelines, ensure accurate and timely completion of deliverables

2) Collaborate with several other teams and roles across the organization on requirements gathering and solution deployment

3) Make analytical product, service or process decisions likely to impact multiple groups of employees and/or customers (internal or external)

4) Manage technology solution portfolios, and identifying new technology approaches to solve business problems with a strong focus on leveraging enterprise data

5) Contribute to the building and management of the analytics infrastructure

6) Work with management team on staffing needs, strategic technology trend identification, monitoring project progress and completion, issue resolution and technical solutions related to data, data flow and advising on algorithm deployment

7) Collaborate with analytics practitioners, business analysts and methodologists to design and oversee the development of working prototypes of technical solutions

8) Technical support and lead for the Data Engineer team

9) Work with project teams to assist with data-related technical issues and support their data infrastructure needs

10) Any ad-hoc tasks requested by your superiors

","1) Bachelor’s degree in Computer Science, Data Science, Software Engineer or in a related field

2) Minimum THREE (3) years of relevant work experience

3) Professional certifications such as; is an added advantage

o Amazon Web Services (AWS)

o Certified Data Analytics

o Google Professional Data Engineer

4) Proven success working with all levels of management

5) Good analytical skills with proven ability to solve problems creatively

6) Good interpersonal skills and resourceful"
Hartalega,Data Analyst,"Plans, develop, implements, and assesses high-level statistical models and strategies in various problems including projections, classification, clustering, pattern analysis, sampling, and simulations.
Develop custom data models and algorithms, use predictive modelling to increase and optimize business outcomes.
Assist in the development of logical and physical data models for designing / developing Business Intelligence / Data Warehouse requirements.
Organize, analyse, and interpret data to uncover patterns, trends and establish how these findings can help to increase the business value through making better informed decisions.
Assess the effectiveness and accuracy of new data sources and data gathering techniques.
Creating new, experimental frameworks to collect data and building tools to automate data collection.
Creating reports and presentation for business uses.","Bachelor’s Degree in Statistics, Math, Computer Science, Economics or equivalent.
Work Experience

Minimum 1-2 years of experience in business analysis and big data management.
Technical and Professional Knowledge

Sound knowledge in SQL, SAS, Python or other analytical tools
Proficient in Excel, PowerPoint, Power BI / Tableau, ODBC connections (SSMS, Access, .Net).
Familiar with system integration, developer Workflows, Model Management, Azure/AWS Machine Learning or big data technology (e.g. Hadoop, Hive, Spark)"
User Experience Researchers Pte Ltd,Business Analyst,"Apply Design Thinking / Service Design methodology and tools to develop and execute the approach to derive the current state and its gaps and challenges, and future states designs and solutions.
Engage with business stakeholders to understand their digital needs, gather requirements, and ensure alignment with overall business goals.
Collaborate with product managers to develop user stories and plan, design and facilitate workshops.
Elicit and document clear and comprehensive requirements, ensuring they are feasible, measurable, and aligned with digital objectives.
Work closely with UX/UI designers and software developers to translate business requirements into well-defined digital solutions and to develop, test and deploy digital solutions.
Conduct in-depth analysis of digital business processes, systems, and workflows to identify areas for improvement and optimization.
Analyze digital data, user behavior, and performance metrics to derive insights and make data-driven recommendations for enhancing digital experiences.
Analyse impact of requested changes and propose improvements to continuously address changing business needs, and work with support team to understand and address technical problems (Operations & Maintenance phase)
Ensure system or product readiness for smooth deployment, adoption and operations
Effectively communicate and present analysis findings, recommendations, and project updates to stakeholders at various levels of the organization.
Collaborate with end-users to define test scenarios and conduct user acceptance testing to ensure digital solutions meet business requirements and deliver a seamless user experience.
Assist in change management activities, including user training, documentation, and support during digital solution implementation and adoption.","How to Succeed:

Minimum 5 years of relevant experience. Candidates with more years of experience will be considered for more senior roles.
Minimum 3 years of relevant experience in enterprise software/web application implementations or development.
Prior working experience in IT business analysis, solutioning design, and testing and support of digital products
Participated in at least one full software or product development cycle, preferably using Agile Methodology
Good experience in end-to-end application implementation including but not limited to areas such as understanding business requirements, and managing the change management
Keen to learn, proactive, dynamic, and with good analytical/conceptual thinking
Excellent written and verbal communication and ability to influence and communicate effectively with non-technical audiences and senior management
Preferred Certifications/Skills:

Business Analysis certification, e.g. Certified Business Analysis Professional (CBAP)
Familiar with the iterative development (Agile) approach
Hands-on work experience of more than 1 year on Design Thinking / Service Design / Process Redesign projects with the development of artifacts such as Service Blueprints, Customer Insights, and Future State Design.
Good understanding of customer/user experience, design thinking, user story mapping, and digital product lifecycle management
Good interpersonal skills with the ability to pitch ideas and influence stakeholders and facilitate discussions to elicit, manage and prioritize product backlog items
Good stakeholder engagement and workshop facilitation skills
Strong analytical, conceptualization and problem-solving skills
Experience with ServiceNow will be preferred.
A driven and motivated personality with an inquisitive mind
Ability to learn and apply knowledge acquired."
FWD Insurance,Senior Data Engineer,"Design, develop, document and implement end-to-end data pipelines and data integration processes, both batch and real-time. This include data analysis, data profiling, data cleansing, data lineage, data mapping, data transformation, developing ETL / ELT jobs and workflows, and deployment of data solutions.
Monitor, recommend, develop and implement ways to improve data quality including reliability, efficiency and cleanliness, and to optimize and fine-tune ETL / ELT processes.
Recommend, execute and deliver best practices in data management and data lifecycle processes, including modular development of ETL / ELT processes, coding and configuration standards, error handling and notification standards, auditing standards, and data archival standards.
Prepare test data, assist to create and execute test plans, test cases and test scripts.
Collaborate with Data Architect, Data Modeler, IT team members, SMEs, vendors and internal business stakeholders, to understand data needs, gather requirements and implement data solutions to deliver business goals.
BAU support for any data issues and change requests, document all investigations, findings, recommendations and resolutions.","Bachelor in IT, Computer Science or Engineering.
At least 3-5 years of using Big Data technologies like Azure and AWS Big Data Solution, Hadoop, Hive, HBase, Spark, Sqoop, Kafka and Spark Streaming.
Minimum 5 years of professional experience in data warehouse, operational data store, and large scale data architecture implementations in Unix or/and Windows environment.
At least 3+ years of solid hands-on development experience with ETL development to transform complex data structure in multiple data sources environment.
At least 5 years data model (relational and/or data warehouse), data mart design and implementation.
Minimum 3-5 years ETL programming in any of these languages including Python, Scala, Java or R
Experience on Azure Databricks for ETL/ELT development and big data analytics programming in Python
Strong Experience with various of ETL/ELT frameworks, data warehousing concepts, data management framework and data lifecycle processes.
Solid understanding on Azure Data Management Solution including Azure Data Factory, Azure Databricks, Azure Blob storage (Gen2) and Azure Synapse"
D Group Holdings Sdn Bhd,Data Analyst,"1. Create weekly and monthly performance reports to show progress on performances of each campaign.

2. Assess data quality, clean, and standardize data from several sources.

3. Identify errors and propose solutions.

4. Analyse data with Excel / any other relevant statistical or analytical tools to identify patterns and insights for performance and process improvement.

5. Present data and reports in suitable templates / dashboards / scorecards and metrics

6. Prepare reports with insights and findings by building a story line with the right data visuals and be ready to present to various level of stakeholders.

7. Maintain and update data, as necessary.

8. Perform Ad-hoc data gathering and analysis to support sales and marketing teams.","1. Work experience as a data analyst or in a related field.

2. Ability to collaborate with stakeholders to assess potential risks.

3. Ability to analyse existing tools and databases and provide software solution recommendations.

4. Ability to translate business requirements into non-technical, lay terms.

5. High-level experience in methodologies and processes for managing large-scale databases.

6. Demonstrated experience in handling large data sets and relational databases.

7. Understanding of addressing and metadata standards.

8. High-level written and verbal communication skills.

9. Degree in Computer Science, Computer Engineering, or related technical discipline; preferably from Local Universities such as UM, USM, UKM, UPM & UTM with CGPA of 3.5 and above."
RHB,Data Engineer,"Developing and maintaining ELT/ETL processes for moving data between systems, optimizing ELT/ETL workflows for performance and efficiency.
Cleaning and preprocessing data to make it suitable for analysis, implementing data transformation processes to convert raw data into a structured, usable format.
Monitoring data pipelines for performance and identifying bottlenecks.
Troubleshooting and resolving issues related to data processing and integration.
Creating documentation to facilitate knowledge transfer and support ongoing maintenance.
Able to effectively engage and communicate with stakeholders & other business units","Bachelor Degree - Bachelor degree or above in Computer Science, Economics, Finance, Mathematics, Statistics or equivalent..

A min. of 0-3 years experience in Data Engineering (banking & insurance experience is a plus)
Knowledge of relational databases and a good command of SQL
Understanding of basic data pipeline design, including data extraction, transformation, and loading processes.

Strong analytical and problem-solving skills.

Proficiency in programming languages: SAS, Python, SQL etc.
Big Data Technologies: Hands-on experience with Hadoop, Spark or similar technologies for large-scale data processing.
Data Quality and Testing: Understanding of data quality checks, monitoring, and testing procedures.
Basic knowledge of data visualization tools (e.g. Tableau, Power BI).
Understanding of statistical analysis, machine learning concepts, modeling conceptual ideas and database management."
Deriv,Senior Data Engineer,"Data Integrity & Security: Ensure data integrity while extracting data from both in-house and third-party complex sources, managing systematic storage while guaranteeing data security, accuracy, and accessibility.


Data Solutions Development: Leverage your expertise in data engineering to provide tangible business solutions and insights that drive informed decision-making.


Data Warehouse Architecture: Design and build a high-performance, secure, and scalable data warehouse and pipeline to support data science projects while following industry best practices.


Debugging & Improvement: Troubleshoot complex issues, recommend improvements, and ensure the efficient functioning of the ETL pipelined architecture.


Data Transformation: Transform raw data into easily digestible tables for Data Analysts, facilitating effective analysis and reporting.


Continuous Learning: Stay updated on company products and new releases to efficiently plan changes in our data warehouse or pipelines as needed.
","Bachelor's degree in Computer Science, Data Engineering, or a related field.


Experience:


Minimum of 7 years in the data engineering field, with a proven track record of successful data pipeline architecture.


Data Modeling Techniques: Expertise in data modeling techniques such as Kimball star schema, Anchor modeling, and Data vault methodologies.


Programming Skills: Competence in object-oriented or functional scripting languages, particularly Python.


Database Proficiency: Strong proficiency in both relational SQL and NoSQL databases, particularly PostgreSQL, with knowledge of PITR, Pg_basebackup, WAL archival, and Replication strategies.


Data Warehousing: Familiarity with column-oriented storage systems or data warehouses such as Parquet, Redshift, and BigQuery.


ETL/ELT Development: In-depth knowledge of developing and maintaining ETL/ELT data pipelines and utilizing workflow management tools like Airflow.


Hands-On GCP Experience: Practical experience with Google Cloud Platform (GCP) services, including BigQuery, scheduled queries, Cloud Storage, and Cloud Functions.


Data Accuracy: Familiarity with alerting and self-recovery methods to maintain data accuracy.


Analytical Skills: Strong analytical skills with an ability to translate complex data into optimal business decisions.


Peer Review Proficiency: Experience in peer reviewing pipeline codes and suggesting improvements.


Communication Skills: Strong communication and presentation skills with fluency in spoken and written English."
Cognizant,Data Engineer,,"Experience in Cloud ETL development activities using Informatica Cloud IICS, including data quality, data reconciliation
Strong SQL experience
Experience/knowledge in Databricks, Snowflake, Python is preferred
Cloud computing using Azure technologies - Azure SQL, Azure SQL DWH, Synapse, ADLS, ADF, Cosmos DB is preferred

Essential Skills: IICS, SQL

Nice to Have Skills: Databricks, Snowflake, Python"
OPC Business Support,Senior Data Engineer,"Expertise in Database technologies, good knowledge of SQL and experience developing across both Relational and NoSQL.
Expertise in message queues such as RabbitMQ, MQTT and distributed streaming platforms such as Apache Kafka.
Hands on experience in Data Warehouse (DWH) environment with data integration/ETL of large and complex data sets.
Hands-on coding experience in Java and Python.
Data modeling skills and schema design for DWH.
Understanding of performance tuning and scaling.
Familiarity with Business Intelligence (BI) and Visualization platforms such as Tableau.
Ability to communicate effectively in English.","Bachelor’s degree in Computer Science or related field (with industry experience).
Proven experience in streaming ETL and distributed streaming using Apache Kafka/KSQL.
6+ years of building large scale data-processing systems with 4+ years in Big Data technologies such as Hadoop and Spark.


Desired Qualifications:
Knowledge of the ELK stack (Elastic, Logstash, Kibana).
Understanding of data analysis and machine learning models.
Experience in the Financial Services industry."
NMG Consulting,Data Analyst,"Own and manage the analysis and reporting of assigned insights programmes: a) Analyse survey data using descriptive and inferential statistics (SAS); b) Summarise analyses through professional looking charts shown in static reports (PowerPoint) and interactive dashboards (PowerBI); c) Deliver insights to clients (internal and external) showing trends and action areas; and d) Manage survey data from different sources – face-to-face interviews, online and phone studies. This includes data import, storage, review and cleansing.
Interact proactively and positively with programme managers and colleagues from other areas of NMG to gain better understanding of the various programmes and deliver accurate outputs: a) Create and maintain continuous improvement actions; and) Review and enhance codes and data structure for more efficient work flow.","Hands-on experience in using MS Power BI, and related MS technologies with a good working knowledge of SAS (Base or EG) and in using SQL and macros. Practical experience in SAS is a MUST
Experience with leading or participating in the gathering and documenting of business logics/methodologies, analysing and reporting survey data
Strong visualisation skills (dashboard and/or graph designing) and academic performance
Knowledge in other programming languages like Python and R with UI/UX experience
Outstanding communication skills at all levels - able to build excellent working relationships with clients, team members and other stakeholders
Ability to solve problems effectively, think creatively and deliver quality outputs in a timely manner and make decisions independently in a fast-paced environment
Excellent attention to detail, organizational, prioritization and time management skills"
CAPCO,Data Analyst,"Manage the build of insights and data assets aligned to business outcomes and strategic data models.
Manage the gathering of detailed data requirements from stakeholders to deliver analytics use cases (e.g. triggers)
Manage the delivery of analytics PoCs that allow our businesses and clients to identify new opportunities
Manage the leveraging of current and emerging data and analytical techniques to address business challenges in an actionable way
Manage the unlocking of opportunities to derive higher returns with improved Data Quality
Management the uncovering of data inconsistencies across consuming systems
Adherence to the Data controls and Governance to check the movement of data
Looking for ways to improve the current systems and processes and automating pipelines where possible","Experience working within Financial Services and Banking as a Business Analyst OR Data Analyst
Strong Python and Pyspark skillsand hands on experience with big data analysis
SQL and Visualization skills are an added advantage and good to have
Good communication and stakeholder management skills
Ability to understand business scenarios and convert them into coding logic
Understanding of agile methods of working (JIRA)
Ability to convert technical problems to business problems and vice-versa"
CBRE,Data Analyst,"Manages the annual Budget process from facilitation of Data Collection to eventual review and analysis of P&Ls. Also manages monthly / quarterly forecasting and strategic planning processes.
Supports Finance teams through periodic training and update on systems / platform processes.
Establishes overall departmental priorities and ensures that all deadlines are met.
Support and manage FP&A finance tools; follow-up with checks to ensure smooth forecast, budget, and month end process. Example:
Set up new finance combos when they appear in the actuals, provide exception report for FP&A to confirm org location,
Add/update a new finance combo when requested by the business
Update OpEx rulebook when new FU is set up, update mapping from ERP to P'Soft
Manage TM1 combos, opening/ closing the tool
Testing of TM1 budget and forecast changes","Degree in Accounting, Finance, or related field preferred.
CPA/CA - fully qualified preferred.
Strong interpersonal and communication skills with the ability to present analysis in a clear and concise manner
Strong reasoning, decision-making, organizational, analytical, and quantitative skills.
Strong computer skills, including specific knowledge of Microsoft Office Suite (Excel, Word, Outlook, PowerPoint, etc.).
Broad experience with other software and financial systems is desired (particularly PowerBi, TM1 and PeopleSoft Financials).
Ability to plan, work in a fast-paced environment and manage multiple projects and work streams. Strong work ethic and adaptable.
Attention to detail, organised and methodical in your approach to work, and the ability to deliver high-quality work under pressure and on time. Ability to adapt to business environment changes.
Role will primarily be working in APAC time zone but will from time to time be required to work beyond APAC time zone."
Prism+,Senior Data Analyst,"Data Collection, Transformation and Storing:

Establish processes to collect and transform internal and relevant external data into structured and usable format, to derive value-added observations and insights.
Data Analysis and Reporting:

Collaborate with different stakeholders to identify data needs and deliver relevant insights.
Develop and maintain data reporting systems and dashboards.
Provide actionable insights through data analysis to support decision-making processes.
Produce and manage interactive dashboards to visualize data trends and metrics.
Data Quality and Integrity:

Ensure the accuracy, completeness, and consistency of data across all data systems.
Conduct regular data quality assessments and implement corrective actions as needed.
Database Management:

Develop and maintain robust database systems to meet the company’s data needs.
Optimize database performance, and manage database security and data protection.
Leadership:

Supervise and mentor data management staff.
Foster a collaborative and innovative team environment.","Bachelor’s degree in Computer Science, Information Systems, Data Management, Business Intelligence, Data Analytics, Statistics, or a related field.
Minimum of 4 years of experience in data management, reporting, analysis, or a related field.
Proven experience in data management, reporting, and data integration projects.
Advanced proficiency in Microsoft Excel and experience with data visualization tools (e.g., Tableau, Power BI) and producing interactive dashboards.
Experience in data warehousing, ETL processes, and data modeling.
Experience in SDLC.
Experience in SQL and/or Python/R.
Experience in Salesforce and Shopify is a plus.
Experience in Airtable and Zapier or other cloud collaboration services, is a plus.
Experience in database management systems (e.g.: AWS suite, MS Azure, MSSQL, etc.) is a plus.
Strong analytical and problem-solving skills.
Excellent organizational and project management abilities.
Effective communication and interpersonal skills."
CIEF Worldwide,Data Research Intern,"Assisting in gathering and organizing data from various sources
Conducting data cleaning, validation, and analysis
Building and maintaining data models and visualizations
Collaborating with team members to identify key business trends and patterns
Creating reports and presentations to communicate findings and recommendations
Assisting in ad-hoc data analysis projects as needed","Currently pursuing a Bachelor's or Master's degree in Business, Economics, Mathematics, Statistics, Computer Science, or a related field
Strong analytical and problem-solving skills
Proficient in data manipulation and analysis using tools such as Excel, SQL or Python
Familiarity with data visualization tools such as Apache Superset, Tableau, Power BI, or Google Data Studio
Solid understanding of statistical concepts and methods
Excellent communication skills, both written and verbal
Ability to work independently and collaboratively in a team environment
Attention to detail and the ability to manage multiple tasks simultaneously
We appreciate if additionally you:

Understand how logistic or finance companies work
Experience in DBT & Snowflake"
MindValley,Data Analyst,"Possess strong technical skills for analyzing diverse datasets, identifying trends and patterns using various variables to model scenarios, and presenting findings for informed decision-making.
Excel as a data storyteller, influencing and supporting other departments by validating comprehensive datasets and assumptions for effective decision-making.
Support stakeholders by challenging ideas, fostering constructive discussions, and resolving conflicting views to achieve positive outcomes.
Design, create, and monitor performance/projects, reporting ongoing and ad hoc metrics through valuable reports, presentations, and dashboards.
Deliver accurate and value-adding actionable insights to drive organisational improvement.
Provide Business Intelligence (BI) reporting on specified KPI areas outlined in the Mindvalley KPI requirements document.
Support ongoing ETL solution changes and implementations.
Ensure the correct flow of data in analytics software backend.
Apply data management practices, identify patterns and trends, address data quality issues, and collaborate with other teams to resolve discrepancies and enhance reporting procedures.","Bachelor's degree in Statistics, Computing, or Computer Science with a quantitative focus.
Over 3 years of relevant experience in Data teams, showcasing successful delivery of measurement solutions/products/models.
Deep understanding of analytics data instrumentation, extraction, and reporting usage.
Proficient in deploying and maintaining reporting data layers and ETL pipelines.
Experience in suggesting Robotic Process Automation/enhancements.
Strong hands-on skills in SQL and a scripting language (e.g., Python).
Advanced data query skills for manipulation through nested and join queries.
Expertise in data visualisation tools like Data Studio, Tableau, Power BI, or similar.
Demonstrated knowledge in ETL design, data warehousing, and database solutions.
Familiarity with cloud product offerings from GCP, Azure, AWS, AlibabaCloud, or similar."